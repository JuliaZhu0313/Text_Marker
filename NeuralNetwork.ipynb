{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Set the context, environment and features"
      ],
      "metadata": {
        "id": "r4ie-x3z7izv"
      },
      "id": "r4ie-x3z7izv"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "99f121f5",
      "metadata": {
        "id": "99f121f5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wacZplDEdoyk",
        "outputId": "e3e39b84-a72e-4ef5-fafc-3f5cfe7ea832"
      },
      "id": "wacZplDEdoyk",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "21b61580",
      "metadata": {
        "id": "21b61580"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Processed_Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "32da489b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "32da489b",
        "outputId": "3c091b31-6b30-46d7-fd96-a0ba96805a41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              full_text  cohesion  syntax  \\\n",
              "0     I think that students would benefit from learn...       3.5     3.5   \n",
              "1     When a problem is a change you have to let it ...       2.5     2.5   \n",
              "2     Dear, Principal\\n\\nIf u change the school poli...       3.0     3.5   \n",
              "3     The best time in life is when you become yours...       4.5     4.5   \n",
              "4     Small act of kindness can impact in other peop...       2.5     3.0   \n",
              "...                                                 ...       ...     ...   \n",
              "3906  I believe using cellphones in class for educat...       2.5     3.0   \n",
              "3907  Working alone, students do not have to argue w...       4.0     4.0   \n",
              "3908  \"A problem is a chance for you to do your best...       2.5     3.0   \n",
              "3909  Many people disagree with Albert Schweitzer's ...       4.0     4.5   \n",
              "3910  Do you think that failure is the main thing fo...       3.5     2.5   \n",
              "\n",
              "      vocabulary  phraseology  grammar  conventions  number_of_words  \\\n",
              "0            3.0          3.0      4.0          3.0              261   \n",
              "1            3.0          2.0      2.0          2.5              533   \n",
              "2            3.0          3.0      3.0          2.5              320   \n",
              "3            4.5          4.5      4.0          5.0              728   \n",
              "4            3.0          3.0      2.5          2.5              234   \n",
              "...          ...          ...      ...          ...              ...   \n",
              "3906         3.0          3.5      2.5          2.5              179   \n",
              "3907         4.0          4.0      3.5          3.0              465   \n",
              "3908         3.0          3.0      3.5          3.0              257   \n",
              "3909         4.5          4.0      4.5          4.5              510   \n",
              "3910         3.5          3.0      3.0          3.5              638   \n",
              "\n",
              "      stopwords_frequency  av_word_per_sen  ...       ttr  coherence_score  \\\n",
              "0                0.498084        14.500000  ...  0.099639         0.422997   \n",
              "1                0.581614        38.071429  ...  0.055175         0.506789   \n",
              "2                0.515625        16.842105  ...  0.073317         0.472376   \n",
              "3                0.559066        20.222222  ...  0.055877         0.412691   \n",
              "4                0.521368        78.000000  ...  0.085833         0.551796   \n",
              "...                   ...              ...  ...       ...              ...   \n",
              "3906             0.430168        29.833333  ...  0.110204         0.593374   \n",
              "3907             0.526882        29.062500  ...  0.067620         0.325690   \n",
              "3908             0.525292        32.125000  ...  0.089931         0.383324   \n",
              "3909             0.527451        24.285714  ...  0.064596         0.444652   \n",
              "3910             0.547022        63.800000  ...  0.054380         0.437314   \n",
              "\n",
              "      lexrank_avg_min_diff  lexrank_interquartile  freq_of_noun  \\\n",
              "0                 0.245068               0.275570      0.203065   \n",
              "1                 0.398650               0.397796      0.200750   \n",
              "2                 0.699098               0.433225      0.221875   \n",
              "3                 0.629558               0.498259      0.188187   \n",
              "4                 0.110281               0.096727      0.230769   \n",
              "...                    ...                    ...           ...   \n",
              "3906              0.062313               0.044963      0.329609   \n",
              "3907              0.327018               0.124590      0.273118   \n",
              "3908              0.388689               0.460645      0.214008   \n",
              "3909              0.510104               0.471795      0.223529   \n",
              "3910              0.417147               0.201592      0.214734   \n",
              "\n",
              "      freq_of_transition  freq_of_pronoun  noun_to_adj  verb_to_adv  \\\n",
              "0               0.065134         0.111111     0.377358     0.317073   \n",
              "1               0.061914         0.103189     0.373832     0.296875   \n",
              "2               0.043750         0.090625     0.380282     0.277778   \n",
              "3               0.043956         0.119505     0.569343     0.184466   \n",
              "4               0.034188         0.119658     0.481481     0.150000   \n",
              "...                  ...              ...          ...          ...   \n",
              "3906            0.072626         0.100559     0.186441     0.315789   \n",
              "3907            0.032258         0.030108     0.370079     0.301887   \n",
              "3908            0.031128         0.120623     0.454545     0.777778   \n",
              "3909            0.027451         0.113725     0.526316     0.638889   \n",
              "3910            0.050157         0.105016     0.299270     0.149425   \n",
              "\n",
              "      phrase_diversity  \n",
              "0             0.119650  \n",
              "1             0.110981  \n",
              "2             0.105634  \n",
              "3             0.105024  \n",
              "4             0.072222  \n",
              "...                ...  \n",
              "3906          0.058876  \n",
              "3907          0.111722  \n",
              "3908          0.353535  \n",
              "3909          0.336257  \n",
              "3910          0.044719  \n",
              "\n",
              "[3911 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7377ef0d-d01a-49c5-8df0-e672a1a78343\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_text</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>syntax</th>\n",
              "      <th>vocabulary</th>\n",
              "      <th>phraseology</th>\n",
              "      <th>grammar</th>\n",
              "      <th>conventions</th>\n",
              "      <th>number_of_words</th>\n",
              "      <th>stopwords_frequency</th>\n",
              "      <th>av_word_per_sen</th>\n",
              "      <th>...</th>\n",
              "      <th>ttr</th>\n",
              "      <th>coherence_score</th>\n",
              "      <th>lexrank_avg_min_diff</th>\n",
              "      <th>lexrank_interquartile</th>\n",
              "      <th>freq_of_noun</th>\n",
              "      <th>freq_of_transition</th>\n",
              "      <th>freq_of_pronoun</th>\n",
              "      <th>noun_to_adj</th>\n",
              "      <th>verb_to_adv</th>\n",
              "      <th>phrase_diversity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I think that students would benefit from learn...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>261</td>\n",
              "      <td>0.498084</td>\n",
              "      <td>14.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.099639</td>\n",
              "      <td>0.422997</td>\n",
              "      <td>0.245068</td>\n",
              "      <td>0.275570</td>\n",
              "      <td>0.203065</td>\n",
              "      <td>0.065134</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.377358</td>\n",
              "      <td>0.317073</td>\n",
              "      <td>0.119650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When a problem is a change you have to let it ...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>533</td>\n",
              "      <td>0.581614</td>\n",
              "      <td>38.071429</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055175</td>\n",
              "      <td>0.506789</td>\n",
              "      <td>0.398650</td>\n",
              "      <td>0.397796</td>\n",
              "      <td>0.200750</td>\n",
              "      <td>0.061914</td>\n",
              "      <td>0.103189</td>\n",
              "      <td>0.373832</td>\n",
              "      <td>0.296875</td>\n",
              "      <td>0.110981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>320</td>\n",
              "      <td>0.515625</td>\n",
              "      <td>16.842105</td>\n",
              "      <td>...</td>\n",
              "      <td>0.073317</td>\n",
              "      <td>0.472376</td>\n",
              "      <td>0.699098</td>\n",
              "      <td>0.433225</td>\n",
              "      <td>0.221875</td>\n",
              "      <td>0.043750</td>\n",
              "      <td>0.090625</td>\n",
              "      <td>0.380282</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.105634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The best time in life is when you become yours...</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>728</td>\n",
              "      <td>0.559066</td>\n",
              "      <td>20.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0.055877</td>\n",
              "      <td>0.412691</td>\n",
              "      <td>0.629558</td>\n",
              "      <td>0.498259</td>\n",
              "      <td>0.188187</td>\n",
              "      <td>0.043956</td>\n",
              "      <td>0.119505</td>\n",
              "      <td>0.569343</td>\n",
              "      <td>0.184466</td>\n",
              "      <td>0.105024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Small act of kindness can impact in other peop...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>234</td>\n",
              "      <td>0.521368</td>\n",
              "      <td>78.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085833</td>\n",
              "      <td>0.551796</td>\n",
              "      <td>0.110281</td>\n",
              "      <td>0.096727</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.034188</td>\n",
              "      <td>0.119658</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>0.072222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3906</th>\n",
              "      <td>I believe using cellphones in class for educat...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>179</td>\n",
              "      <td>0.430168</td>\n",
              "      <td>29.833333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.110204</td>\n",
              "      <td>0.593374</td>\n",
              "      <td>0.062313</td>\n",
              "      <td>0.044963</td>\n",
              "      <td>0.329609</td>\n",
              "      <td>0.072626</td>\n",
              "      <td>0.100559</td>\n",
              "      <td>0.186441</td>\n",
              "      <td>0.315789</td>\n",
              "      <td>0.058876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>Working alone, students do not have to argue w...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>465</td>\n",
              "      <td>0.526882</td>\n",
              "      <td>29.062500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.067620</td>\n",
              "      <td>0.325690</td>\n",
              "      <td>0.327018</td>\n",
              "      <td>0.124590</td>\n",
              "      <td>0.273118</td>\n",
              "      <td>0.032258</td>\n",
              "      <td>0.030108</td>\n",
              "      <td>0.370079</td>\n",
              "      <td>0.301887</td>\n",
              "      <td>0.111722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3908</th>\n",
              "      <td>\"A problem is a chance for you to do your best...</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>257</td>\n",
              "      <td>0.525292</td>\n",
              "      <td>32.125000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.089931</td>\n",
              "      <td>0.383324</td>\n",
              "      <td>0.388689</td>\n",
              "      <td>0.460645</td>\n",
              "      <td>0.214008</td>\n",
              "      <td>0.031128</td>\n",
              "      <td>0.120623</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.353535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>Many people disagree with Albert Schweitzer's ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>510</td>\n",
              "      <td>0.527451</td>\n",
              "      <td>24.285714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.064596</td>\n",
              "      <td>0.444652</td>\n",
              "      <td>0.510104</td>\n",
              "      <td>0.471795</td>\n",
              "      <td>0.223529</td>\n",
              "      <td>0.027451</td>\n",
              "      <td>0.113725</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.336257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>Do you think that failure is the main thing fo...</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>638</td>\n",
              "      <td>0.547022</td>\n",
              "      <td>63.800000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054380</td>\n",
              "      <td>0.437314</td>\n",
              "      <td>0.417147</td>\n",
              "      <td>0.201592</td>\n",
              "      <td>0.214734</td>\n",
              "      <td>0.050157</td>\n",
              "      <td>0.105016</td>\n",
              "      <td>0.299270</td>\n",
              "      <td>0.149425</td>\n",
              "      <td>0.044719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3911 rows × 43 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7377ef0d-d01a-49c5-8df0-e672a1a78343')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7377ef0d-d01a-49c5-8df0-e672a1a78343 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7377ef0d-d01a-49c5-8df0-e672a1a78343');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8c292af5",
      "metadata": {
        "id": "8c292af5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "T1oI8r4E9yva"
      },
      "id": "T1oI8r4E9yva",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = pd.concat([df.iloc[:,7:], df['cohesion'], df['vocabulary']], axis = 1)\n",
        "train_data, test_data = train_test_split(selected_features, test_size= 0.2,  random_state = 2)"
      ],
      "metadata": {
        "id": "w4Zm1Q4aq0Dg"
      },
      "id": "w4Zm1Q4aq0Dg",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5IjJ2o_2_DC",
        "outputId": "365c0b0e-0ffc-45a9-de04-58d12b9d54e8"
      },
      "id": "L5IjJ2o_2_DC",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(783, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "WlVle9Twq-rb",
        "outputId": "00feb489-72d5-4a7d-8613-1e7c00b6c829"
      },
      "id": "WlVle9Twq-rb",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      number_of_words  stopwords_frequency  av_word_per_sen  punctuations  \\\n",
              "1749              389             0.437018        14.961538      0.075650   \n",
              "2304              320             0.440625        21.333333      0.084270   \n",
              "2458              228             0.368421        15.200000      0.061728   \n",
              "1383              457             0.509847        19.869565      0.060241   \n",
              "1354              455             0.595604        75.833333      0.042194   \n",
              "...               ...                  ...              ...           ...   \n",
              "3606              277             0.487365        11.080000      0.082508   \n",
              "1608              283             0.551237        28.300000      0.080645   \n",
              "2541              305             0.419672        12.200000      0.130790   \n",
              "2575              847             0.521842        29.206897      0.057650   \n",
              "3240              363             0.504132        24.200000      0.048593   \n",
              "\n",
              "      ARI  freq_of_verb  freq_of_adj  freq_of_adv  freq_of_distinct_adj  \\\n",
              "1749    6      0.089974     0.105398     0.010283              0.071979   \n",
              "2304    9      0.140625     0.056250     0.065625              0.050000   \n",
              "2458    6      0.109649     0.122807     0.078947              0.052632   \n",
              "1383    8      0.098468     0.098468     0.028446              0.056893   \n",
              "1354   34      0.079121     0.090110     0.039560              0.065934   \n",
              "...   ...           ...          ...          ...                   ...   \n",
              "3606    4      0.068592     0.072202     0.061372              0.061372   \n",
              "1608   12      0.102473     0.084806     0.067138              0.077739   \n",
              "2541    6      0.121311     0.118033     0.068852              0.055738   \n",
              "2575   13      0.120425     0.064935     0.029516              0.049587   \n",
              "3240   12      0.126722     0.085399     0.030303              0.052342   \n",
              "\n",
              "      freq_of_distinct_adv  ...  lexrank_avg_min_diff  lexrank_interquartile  \\\n",
              "1749              0.007712  ...              0.583806               0.545659   \n",
              "2304              0.021875  ...              0.518039               0.277898   \n",
              "2458              0.048246  ...              0.713681               0.509217   \n",
              "1383              0.019694  ...              0.578532               0.800124   \n",
              "1354              0.021978  ...              0.287504               0.148577   \n",
              "...                    ...  ...                   ...                    ...   \n",
              "3606              0.046931  ...              0.559748               0.224948   \n",
              "1608              0.021201  ...              0.249115               0.261299   \n",
              "2541              0.026230  ...              0.532533               0.448009   \n",
              "2575              0.010626  ...              0.704079               0.609323   \n",
              "3240              0.024793  ...              0.447981               0.799422   \n",
              "\n",
              "      freq_of_noun  freq_of_transition  freq_of_pronoun  noun_to_adj  \\\n",
              "1749      0.316195            0.046272         0.095116     0.333333   \n",
              "2304      0.303125            0.031250         0.081250     0.185567   \n",
              "2458      0.250000            0.008772         0.065789     0.491228   \n",
              "1383      0.216630            0.050328         0.113786     0.454545   \n",
              "1354      0.219780            0.057143         0.142857     0.410000   \n",
              "...            ...                 ...              ...          ...   \n",
              "3606      0.277978            0.039711         0.126354     0.259740   \n",
              "1608      0.197880            0.042403         0.098940     0.428571   \n",
              "2541      0.242623            0.049180         0.075410     0.486486   \n",
              "2575      0.251476            0.061393         0.112161     0.258216   \n",
              "3240      0.269972            0.044077         0.057851     0.316327   \n",
              "\n",
              "     verb_to_adv  phrase_diversity  cohesion  vocabulary  \n",
              "1749    0.114286          0.038095       3.5         4.0  \n",
              "2304    0.466667          0.086598       3.0         2.0  \n",
              "2458    0.720000          0.353684       3.5         3.5  \n",
              "1383    0.288889          0.131313       4.0         4.5  \n",
              "1354    0.500000          0.205000       2.5         3.0  \n",
              "...          ...               ...       ...         ...  \n",
              "3606    0.894737          0.232399       3.5         3.5  \n",
              "1608    0.655172          0.280788       3.5         3.0  \n",
              "2541    0.567568          0.276114       2.5         3.0  \n",
              "2575    0.245098          0.063288       3.5         3.0  \n",
              "3240    0.239130          0.075643       3.5         3.5  \n",
              "\n",
              "[3128 rows x 38 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca3692f2-2769-4e61-82a1-e157d74a53b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number_of_words</th>\n",
              "      <th>stopwords_frequency</th>\n",
              "      <th>av_word_per_sen</th>\n",
              "      <th>punctuations</th>\n",
              "      <th>ARI</th>\n",
              "      <th>freq_of_verb</th>\n",
              "      <th>freq_of_adj</th>\n",
              "      <th>freq_of_adv</th>\n",
              "      <th>freq_of_distinct_adj</th>\n",
              "      <th>freq_of_distinct_adv</th>\n",
              "      <th>...</th>\n",
              "      <th>lexrank_avg_min_diff</th>\n",
              "      <th>lexrank_interquartile</th>\n",
              "      <th>freq_of_noun</th>\n",
              "      <th>freq_of_transition</th>\n",
              "      <th>freq_of_pronoun</th>\n",
              "      <th>noun_to_adj</th>\n",
              "      <th>verb_to_adv</th>\n",
              "      <th>phrase_diversity</th>\n",
              "      <th>cohesion</th>\n",
              "      <th>vocabulary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1749</th>\n",
              "      <td>389</td>\n",
              "      <td>0.437018</td>\n",
              "      <td>14.961538</td>\n",
              "      <td>0.075650</td>\n",
              "      <td>6</td>\n",
              "      <td>0.089974</td>\n",
              "      <td>0.105398</td>\n",
              "      <td>0.010283</td>\n",
              "      <td>0.071979</td>\n",
              "      <td>0.007712</td>\n",
              "      <td>...</td>\n",
              "      <td>0.583806</td>\n",
              "      <td>0.545659</td>\n",
              "      <td>0.316195</td>\n",
              "      <td>0.046272</td>\n",
              "      <td>0.095116</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.114286</td>\n",
              "      <td>0.038095</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2304</th>\n",
              "      <td>320</td>\n",
              "      <td>0.440625</td>\n",
              "      <td>21.333333</td>\n",
              "      <td>0.084270</td>\n",
              "      <td>9</td>\n",
              "      <td>0.140625</td>\n",
              "      <td>0.056250</td>\n",
              "      <td>0.065625</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.021875</td>\n",
              "      <td>...</td>\n",
              "      <td>0.518039</td>\n",
              "      <td>0.277898</td>\n",
              "      <td>0.303125</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.081250</td>\n",
              "      <td>0.185567</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.086598</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2458</th>\n",
              "      <td>228</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>15.200000</td>\n",
              "      <td>0.061728</td>\n",
              "      <td>6</td>\n",
              "      <td>0.109649</td>\n",
              "      <td>0.122807</td>\n",
              "      <td>0.078947</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.048246</td>\n",
              "      <td>...</td>\n",
              "      <td>0.713681</td>\n",
              "      <td>0.509217</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>0.065789</td>\n",
              "      <td>0.491228</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.353684</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1383</th>\n",
              "      <td>457</td>\n",
              "      <td>0.509847</td>\n",
              "      <td>19.869565</td>\n",
              "      <td>0.060241</td>\n",
              "      <td>8</td>\n",
              "      <td>0.098468</td>\n",
              "      <td>0.098468</td>\n",
              "      <td>0.028446</td>\n",
              "      <td>0.056893</td>\n",
              "      <td>0.019694</td>\n",
              "      <td>...</td>\n",
              "      <td>0.578532</td>\n",
              "      <td>0.800124</td>\n",
              "      <td>0.216630</td>\n",
              "      <td>0.050328</td>\n",
              "      <td>0.113786</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.288889</td>\n",
              "      <td>0.131313</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1354</th>\n",
              "      <td>455</td>\n",
              "      <td>0.595604</td>\n",
              "      <td>75.833333</td>\n",
              "      <td>0.042194</td>\n",
              "      <td>34</td>\n",
              "      <td>0.079121</td>\n",
              "      <td>0.090110</td>\n",
              "      <td>0.039560</td>\n",
              "      <td>0.065934</td>\n",
              "      <td>0.021978</td>\n",
              "      <td>...</td>\n",
              "      <td>0.287504</td>\n",
              "      <td>0.148577</td>\n",
              "      <td>0.219780</td>\n",
              "      <td>0.057143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.205000</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3606</th>\n",
              "      <td>277</td>\n",
              "      <td>0.487365</td>\n",
              "      <td>11.080000</td>\n",
              "      <td>0.082508</td>\n",
              "      <td>4</td>\n",
              "      <td>0.068592</td>\n",
              "      <td>0.072202</td>\n",
              "      <td>0.061372</td>\n",
              "      <td>0.061372</td>\n",
              "      <td>0.046931</td>\n",
              "      <td>...</td>\n",
              "      <td>0.559748</td>\n",
              "      <td>0.224948</td>\n",
              "      <td>0.277978</td>\n",
              "      <td>0.039711</td>\n",
              "      <td>0.126354</td>\n",
              "      <td>0.259740</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.232399</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1608</th>\n",
              "      <td>283</td>\n",
              "      <td>0.551237</td>\n",
              "      <td>28.300000</td>\n",
              "      <td>0.080645</td>\n",
              "      <td>12</td>\n",
              "      <td>0.102473</td>\n",
              "      <td>0.084806</td>\n",
              "      <td>0.067138</td>\n",
              "      <td>0.077739</td>\n",
              "      <td>0.021201</td>\n",
              "      <td>...</td>\n",
              "      <td>0.249115</td>\n",
              "      <td>0.261299</td>\n",
              "      <td>0.197880</td>\n",
              "      <td>0.042403</td>\n",
              "      <td>0.098940</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.280788</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2541</th>\n",
              "      <td>305</td>\n",
              "      <td>0.419672</td>\n",
              "      <td>12.200000</td>\n",
              "      <td>0.130790</td>\n",
              "      <td>6</td>\n",
              "      <td>0.121311</td>\n",
              "      <td>0.118033</td>\n",
              "      <td>0.068852</td>\n",
              "      <td>0.055738</td>\n",
              "      <td>0.026230</td>\n",
              "      <td>...</td>\n",
              "      <td>0.532533</td>\n",
              "      <td>0.448009</td>\n",
              "      <td>0.242623</td>\n",
              "      <td>0.049180</td>\n",
              "      <td>0.075410</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.276114</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2575</th>\n",
              "      <td>847</td>\n",
              "      <td>0.521842</td>\n",
              "      <td>29.206897</td>\n",
              "      <td>0.057650</td>\n",
              "      <td>13</td>\n",
              "      <td>0.120425</td>\n",
              "      <td>0.064935</td>\n",
              "      <td>0.029516</td>\n",
              "      <td>0.049587</td>\n",
              "      <td>0.010626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.704079</td>\n",
              "      <td>0.609323</td>\n",
              "      <td>0.251476</td>\n",
              "      <td>0.061393</td>\n",
              "      <td>0.112161</td>\n",
              "      <td>0.258216</td>\n",
              "      <td>0.245098</td>\n",
              "      <td>0.063288</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3240</th>\n",
              "      <td>363</td>\n",
              "      <td>0.504132</td>\n",
              "      <td>24.200000</td>\n",
              "      <td>0.048593</td>\n",
              "      <td>12</td>\n",
              "      <td>0.126722</td>\n",
              "      <td>0.085399</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.052342</td>\n",
              "      <td>0.024793</td>\n",
              "      <td>...</td>\n",
              "      <td>0.447981</td>\n",
              "      <td>0.799422</td>\n",
              "      <td>0.269972</td>\n",
              "      <td>0.044077</td>\n",
              "      <td>0.057851</td>\n",
              "      <td>0.316327</td>\n",
              "      <td>0.239130</td>\n",
              "      <td>0.075643</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3128 rows × 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca3692f2-2769-4e61-82a1-e157d74a53b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca3692f2-2769-4e61-82a1-e157d74a53b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca3692f2-2769-4e61-82a1-e157d74a53b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = []\n",
        "coherence_score = tf.feature_column.numeric_column(\"coherence_score\")\n",
        "feature_columns.append(coherence_score)\n",
        "ttr = tf.feature_column.numeric_column(\"ttr\")\n",
        "feature_columns.append(ttr)\n",
        "freq_diff_words = tf.feature_column.numeric_column(\"freq_diff_words\")\n",
        "feature_columns.append(freq_diff_words)\n",
        "number_of_diff_words = tf.feature_column.numeric_column(\"number_of_diff_words\")\n",
        "feature_columns.append(number_of_diff_words)\n",
        "dale = tf.feature_column.numeric_column(\"dale_chall_readability_score\")\n",
        "feature_columns.append(dale)\n",
        "mcalpine_eflaw = tf.feature_column.numeric_column(\"mcalpine_eflaw\")\n",
        "feature_columns.append(mcalpine_eflaw)\n",
        "ts = tf.feature_column.numeric_column(\"text_standard\")\n",
        "feature_columns.append(ts)\n",
        "\n",
        "fle = tf.feature_column.numeric_column(\"flesch_kincaid_grade\")\n",
        "feature_columns.append(fle)\n",
        "disadv = tf.feature_column.numeric_column(\"freq_of_distinct_adv\")\n",
        "feature_columns.append(disadv)\n",
        "disadj = tf.feature_column.numeric_column(\"freq_of_distinct_adj\")\n",
        "feature_columns.append(disadj)\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"freq_of_adv\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"freq_of_adj\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"freq_of_verb\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"ARI\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"punctuations\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"av_word_per_sen\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"stopwords_frequency\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"number_of_words\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"flesch_reading_ease\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"Incorrect_form_ratio\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"num_of_short_forms\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"num_of_grammar_errors\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"sentiment_negative\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"sentiment_positive\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"sentiment_compound\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"freq_of_wrong_words\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"sentence_complexity\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"lexrank_avg_min_diff\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"lexrank_interquartile\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"freq_of_noun\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"freq_of_transition\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"freq_of_pronoun\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"noun_to_adj\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"verb_to_adv\"))\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"phrase_diversity\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "feature_columns.append(tf.feature_column.numeric_column(\"vocabulary\"))\n",
        "my_new_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n"
      ],
      "metadata": {
        "id": "IcQ9UFogJYdM"
      },
      "id": "IcQ9UFogJYdM",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(feature_columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKcJEGREsD3e",
        "outputId": "9b630732-5f57-472a-a85a-8235ef643b32"
      },
      "id": "yKcJEGREsD3e",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_the_loss_curve(mse_train, mse_val):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Mean Squared Error\")\n",
        "\n",
        "  plt.plot(mse_train, label=\"Training Loss\")\n",
        "  plt.plot(mse_val, label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "  # plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
        "  plt.show()  "
      ],
      "metadata": {
        "id": "6XNeGAJdIS1O"
      },
      "id": "6XNeGAJdIS1O",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_linear(my_learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(30, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(100, activation = 'relu'))\n",
        "  model.add(tf.keras.layers.Dense(units=1))\n",
        "  \n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\", \n",
        "                metrics=[tf.keras.metrics.MeanSquaredError(), \"accuracy\"])\n",
        "  return model           "
      ],
      "metadata": {
        "id": "nS6wtyT7IdAh"
      },
      "id": "nS6wtyT7IdAh",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataset, epochs, batch_size, label_name):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=0.2, shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  mse_train = history.history['loss']\n",
        "  mse_val = history.history['val_loss']\n",
        "\n",
        "  return mse_train, mse_val"
      ],
      "metadata": {
        "id": "sDo8D5FBJPBo"
      },
      "id": "sDo8D5FBJPBo",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on vocabulary"
      ],
      "metadata": {
        "id": "J5RhHCPS_hgy"
      },
      "id": "J5RhHCPS_hgy"
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "number_epochs = 30\n",
        "batch_size = 256\n",
        "label_name = \"vocabulary\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "model_lr = create_model_linear(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "mse_train_lr, mse_val_lr = train_model(model_lr, train_data, number_epochs, batch_size, label_name)\n",
        "#train_history = train_model(model_lr, train_data, number_epochs, batch_size, label_name)\n",
        "plot_the_loss_curve(mse_train_lr, mse_val_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jWQ4CvBJOZ9o",
        "outputId": "77a7c150-722a-4db7-9d72-698a94435b6e"
      },
      "id": "jWQ4CvBJOZ9o",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/10 [==>...........................] - ETA: 12s - loss: 223.6973 - mean_squared_error: 223.6973 - accuracy: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 2s 75ms/step - loss: 9875.6846 - mean_squared_error: 9875.6846 - accuracy: 0.0000e+00 - val_loss: 3.3110 - val_mean_squared_error: 3.3110 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 8.2785 - mean_squared_error: 8.2785 - accuracy: 0.0000e+00 - val_loss: 151.1998 - val_mean_squared_error: 151.1998 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 236.5699 - mean_squared_error: 236.5699 - accuracy: 0.0000e+00 - val_loss: 205.3056 - val_mean_squared_error: 205.3056 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 257.6559 - mean_squared_error: 257.6559 - accuracy: 0.0000e+00 - val_loss: 412.3067 - val_mean_squared_error: 412.3067 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 177.7565 - mean_squared_error: 177.7565 - accuracy: 0.0000e+00 - val_loss: 192.4398 - val_mean_squared_error: 192.4398 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 210.2557 - mean_squared_error: 210.2557 - accuracy: 0.0000e+00 - val_loss: 38.2268 - val_mean_squared_error: 38.2268 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 108.1762 - mean_squared_error: 108.1762 - accuracy: 0.0000e+00 - val_loss: 93.9118 - val_mean_squared_error: 93.9118 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 26.6585 - mean_squared_error: 26.6585 - accuracy: 0.0000e+00 - val_loss: 45.0724 - val_mean_squared_error: 45.0724 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 69.3576 - mean_squared_error: 69.3576 - accuracy: 0.0000e+00 - val_loss: 2.2176 - val_mean_squared_error: 2.2176 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.5437 - mean_squared_error: 4.5437 - accuracy: 0.0000e+00 - val_loss: 55.4179 - val_mean_squared_error: 55.4179 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 40.6099 - mean_squared_error: 40.6099 - accuracy: 0.0000e+00 - val_loss: 4.0686 - val_mean_squared_error: 4.0686 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 9.2805 - mean_squared_error: 9.2805 - accuracy: 0.0000e+00 - val_loss: 16.0188 - val_mean_squared_error: 16.0188 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 7.4498 - mean_squared_error: 7.4498 - accuracy: 0.0000e+00 - val_loss: 8.7264 - val_mean_squared_error: 8.7264 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.0432 - mean_squared_error: 4.0432 - accuracy: 0.0000e+00 - val_loss: 8.8041 - val_mean_squared_error: 8.8041 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.5666 - mean_squared_error: 3.5666 - accuracy: 0.0000e+00 - val_loss: 3.8610 - val_mean_squared_error: 3.8610 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.3339 - mean_squared_error: 3.3339 - accuracy: 0.0000e+00 - val_loss: 3.5543 - val_mean_squared_error: 3.5543 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.9855 - mean_squared_error: 2.9855 - accuracy: 0.0000e+00 - val_loss: 1.9981 - val_mean_squared_error: 1.9981 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8664 - mean_squared_error: 1.8664 - accuracy: 0.0000e+00 - val_loss: 1.0004 - val_mean_squared_error: 1.0004 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.9923 - mean_squared_error: 1.9923 - accuracy: 0.0000e+00 - val_loss: 0.8548 - val_mean_squared_error: 0.8548 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.2155 - mean_squared_error: 1.2155 - accuracy: 0.0000e+00 - val_loss: 2.1381 - val_mean_squared_error: 2.1381 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4414 - mean_squared_error: 1.4414 - accuracy: 0.0000e+00 - val_loss: 1.1405 - val_mean_squared_error: 1.1405 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9245 - mean_squared_error: 0.9245 - accuracy: 0.0000e+00 - val_loss: 0.9315 - val_mean_squared_error: 0.9315 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.8795 - mean_squared_error: 0.8795 - accuracy: 0.0000e+00 - val_loss: 0.8358 - val_mean_squared_error: 0.8358 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8733 - mean_squared_error: 0.8733 - accuracy: 0.0000e+00 - val_loss: 1.0012 - val_mean_squared_error: 1.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.8007 - mean_squared_error: 0.8007 - accuracy: 0.0000e+00 - val_loss: 0.7698 - val_mean_squared_error: 0.7698 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7345 - mean_squared_error: 0.7345 - accuracy: 0.0000e+00 - val_loss: 0.7784 - val_mean_squared_error: 0.7784 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6711 - mean_squared_error: 0.6711 - accuracy: 0.0000e+00 - val_loss: 0.8739 - val_mean_squared_error: 0.8739 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.6662 - mean_squared_error: 0.6662 - accuracy: 0.0000e+00 - val_loss: 0.9593 - val_mean_squared_error: 0.9593 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6036 - mean_squared_error: 0.6036 - accuracy: 0.0000e+00 - val_loss: 0.5113 - val_mean_squared_error: 0.5113 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5546 - mean_squared_error: 0.5546 - accuracy: 0.0000e+00 - val_loss: 0.5416 - val_mean_squared_error: 0.5416 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label2 = \"cohesion\"\n",
        "test_data.pop(\"corrected_text\")\n",
        "test_features = {name:np.array(value) for name, value in test_data.items()}\n",
        "test_features.pop(label2)\n",
        "test_label = np.array(test_features.pop(label_name))# isolate the label\n",
        "\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "result = model_lr.evaluate(x=test_features, y=test_label, batch_size=batch_size)\n",
        "\n",
        "for item in zip(model_lr.metrics_names, result):\n",
        "  print (item[0], item[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6y1Cn30OZ2H",
        "outputId": "6eb855c0-22ff-4080-8ea8-363d36a849cc"
      },
      "id": "v6y1Cn30OZ2H",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4978 - mean_squared_error: 0.4978 - accuracy: 0.0026\n",
            "loss 0.4978398382663727\n",
            "mean_squared_error 0.4978398382663727\n",
            "accuracy 0.0025542783550918102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model_lr.predict(test_features)\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbpJnaDCt81n",
        "outputId": "26f7242f-2083-4baa-ac48-48145ac8bc3c"
      },
      "id": "lbpJnaDCt81n",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.087934 ],\n",
              "       [2.3907206],\n",
              "       [2.5340405],\n",
              "       [2.7715821],\n",
              "       [3.2123504],\n",
              "       [2.637723 ],\n",
              "       [2.3865767],\n",
              "       [2.5760376],\n",
              "       [2.61243  ],\n",
              "       [3.1120706],\n",
              "       [2.7342293],\n",
              "       [2.6894577],\n",
              "       [2.621704 ],\n",
              "       [2.7279654],\n",
              "       [2.5878487],\n",
              "       [2.5921931],\n",
              "       [2.6760137],\n",
              "       [3.1607332],\n",
              "       [2.5346415],\n",
              "       [2.1126435],\n",
              "       [5.262104 ],\n",
              "       [2.7177455],\n",
              "       [3.1121163],\n",
              "       [2.7018511],\n",
              "       [2.7561045],\n",
              "       [2.5704627],\n",
              "       [2.9105508],\n",
              "       [2.7058897],\n",
              "       [2.9268079],\n",
              "       [2.892447 ],\n",
              "       [2.6343315],\n",
              "       [2.5326185],\n",
              "       [2.8605757],\n",
              "       [3.3883715],\n",
              "       [2.7959654],\n",
              "       [3.0047917],\n",
              "       [2.5082111],\n",
              "       [3.445657 ],\n",
              "       [2.8015785],\n",
              "       [2.5148356],\n",
              "       [2.8584542],\n",
              "       [2.5306435],\n",
              "       [2.840991 ],\n",
              "       [3.05191  ],\n",
              "       [2.3350542],\n",
              "       [2.7909112],\n",
              "       [2.6749847],\n",
              "       [2.8465385],\n",
              "       [2.7454715],\n",
              "       [2.5800307],\n",
              "       [2.3242743],\n",
              "       [2.5719104],\n",
              "       [2.6256485],\n",
              "       [2.5045896],\n",
              "       [2.5289342],\n",
              "       [2.530233 ],\n",
              "       [2.9641824],\n",
              "       [3.1528592],\n",
              "       [2.8895843],\n",
              "       [2.550094 ],\n",
              "       [2.6586332],\n",
              "       [3.3470652],\n",
              "       [2.6336482],\n",
              "       [2.6740878],\n",
              "       [2.9766445],\n",
              "       [2.9236917],\n",
              "       [1.9101   ],\n",
              "       [3.064558 ],\n",
              "       [2.4134364],\n",
              "       [2.7062173],\n",
              "       [2.1034465],\n",
              "       [2.9382033],\n",
              "       [2.5099275],\n",
              "       [2.501094 ],\n",
              "       [3.001261 ],\n",
              "       [2.676877 ],\n",
              "       [3.096037 ],\n",
              "       [3.4512901],\n",
              "       [2.801224 ],\n",
              "       [2.3277197],\n",
              "       [2.6308131],\n",
              "       [2.5464962],\n",
              "       [2.7043889],\n",
              "       [2.5170124],\n",
              "       [2.8327498],\n",
              "       [2.6751745],\n",
              "       [2.8526363],\n",
              "       [2.6426654],\n",
              "       [2.7245007],\n",
              "       [2.6618505],\n",
              "       [2.8642814],\n",
              "       [2.6826732],\n",
              "       [2.8887806],\n",
              "       [2.2694597],\n",
              "       [2.5840936],\n",
              "       [2.6939259],\n",
              "       [2.7414036],\n",
              "       [3.3231206],\n",
              "       [3.0125597],\n",
              "       [2.4580283],\n",
              "       [2.7942398],\n",
              "       [2.324412 ],\n",
              "       [2.610935 ],\n",
              "       [2.895425 ],\n",
              "       [2.8714304],\n",
              "       [2.99398  ],\n",
              "       [2.6735907],\n",
              "       [2.5883367],\n",
              "       [2.515838 ],\n",
              "       [2.5738158],\n",
              "       [3.1582346],\n",
              "       [2.9129739],\n",
              "       [2.4316382],\n",
              "       [2.7045379],\n",
              "       [2.5069854],\n",
              "       [2.5741765],\n",
              "       [2.7464175],\n",
              "       [2.8429842],\n",
              "       [2.5991905],\n",
              "       [2.6862564],\n",
              "       [2.3008633],\n",
              "       [2.9380221],\n",
              "       [2.6719232],\n",
              "       [2.631132 ],\n",
              "       [2.5203404],\n",
              "       [2.192741 ],\n",
              "       [2.843439 ],\n",
              "       [3.1555815],\n",
              "       [2.8524358],\n",
              "       [2.828918 ],\n",
              "       [2.5359445],\n",
              "       [3.088293 ],\n",
              "       [2.7816753],\n",
              "       [2.7650716],\n",
              "       [3.0529046],\n",
              "       [2.8475306],\n",
              "       [2.449153 ],\n",
              "       [2.7263968],\n",
              "       [2.7424796],\n",
              "       [2.4498858],\n",
              "       [2.4203413],\n",
              "       [3.06628  ],\n",
              "       [2.732994 ],\n",
              "       [2.9942925],\n",
              "       [2.958898 ],\n",
              "       [2.9271588],\n",
              "       [2.617529 ],\n",
              "       [3.1190991],\n",
              "       [2.9536178],\n",
              "       [2.513453 ],\n",
              "       [2.771368 ],\n",
              "       [2.9718485],\n",
              "       [2.954618 ],\n",
              "       [2.6136677],\n",
              "       [2.6650555],\n",
              "       [2.5495105],\n",
              "       [2.452477 ],\n",
              "       [2.6742964],\n",
              "       [2.6253378],\n",
              "       [2.5467985],\n",
              "       [2.89267  ],\n",
              "       [2.8362515],\n",
              "       [2.6455383],\n",
              "       [2.4393282],\n",
              "       [2.670198 ],\n",
              "       [2.7271552],\n",
              "       [2.2321503],\n",
              "       [3.0284562],\n",
              "       [2.7342873],\n",
              "       [2.4926062],\n",
              "       [2.497082 ],\n",
              "       [2.7096112],\n",
              "       [2.2956276],\n",
              "       [2.630373 ],\n",
              "       [2.8828535],\n",
              "       [2.6234517],\n",
              "       [2.6802397],\n",
              "       [2.742958 ],\n",
              "       [2.8029857],\n",
              "       [2.8687854],\n",
              "       [2.7837234],\n",
              "       [3.2555225],\n",
              "       [2.5900788],\n",
              "       [2.4839673],\n",
              "       [2.5860045],\n",
              "       [2.5687268],\n",
              "       [2.6903691],\n",
              "       [3.1583424],\n",
              "       [2.6657066],\n",
              "       [2.8262584],\n",
              "       [2.4285512],\n",
              "       [2.7020638],\n",
              "       [3.1560686],\n",
              "       [2.4930544],\n",
              "       [2.5502236],\n",
              "       [3.41854  ],\n",
              "       [3.8959813],\n",
              "       [2.62642  ],\n",
              "       [3.6829107],\n",
              "       [2.9160454],\n",
              "       [2.4706938],\n",
              "       [2.6540034],\n",
              "       [2.859364 ],\n",
              "       [2.7352984],\n",
              "       [2.859222 ],\n",
              "       [3.1358619],\n",
              "       [3.1338458],\n",
              "       [3.0784614],\n",
              "       [2.8994021],\n",
              "       [2.4177444],\n",
              "       [2.6771042],\n",
              "       [2.4112926],\n",
              "       [3.5022972],\n",
              "       [2.2959814],\n",
              "       [2.6428182],\n",
              "       [2.6779675],\n",
              "       [2.9431672],\n",
              "       [2.778224 ],\n",
              "       [2.9709103],\n",
              "       [3.1169968],\n",
              "       [3.2205522],\n",
              "       [3.122074 ],\n",
              "       [3.0010858],\n",
              "       [3.3470817],\n",
              "       [2.7779403],\n",
              "       [2.6677382],\n",
              "       [2.4704792],\n",
              "       [2.740599 ],\n",
              "       [2.6070402],\n",
              "       [2.929963 ],\n",
              "       [2.471603 ],\n",
              "       [2.848081 ],\n",
              "       [2.7249432],\n",
              "       [2.4109943],\n",
              "       [2.5657513],\n",
              "       [2.4644623],\n",
              "       [3.0920975],\n",
              "       [2.1127903],\n",
              "       [2.8998196],\n",
              "       [3.541017 ],\n",
              "       [2.4855137],\n",
              "       [2.5055146],\n",
              "       [3.0533109],\n",
              "       [3.1715589],\n",
              "       [2.7794366],\n",
              "       [2.7841964],\n",
              "       [2.9003024],\n",
              "       [2.7433684],\n",
              "       [2.9026856],\n",
              "       [2.5877795],\n",
              "       [2.5444608],\n",
              "       [3.0104132],\n",
              "       [3.078929 ],\n",
              "       [2.4689212],\n",
              "       [2.5616717],\n",
              "       [3.5124261],\n",
              "       [2.5632374],\n",
              "       [2.7343483],\n",
              "       [3.0209827],\n",
              "       [3.1265662],\n",
              "       [2.6914659],\n",
              "       [2.8694916],\n",
              "       [2.4732609],\n",
              "       [2.769114 ],\n",
              "       [3.2199886],\n",
              "       [2.9652414],\n",
              "       [2.6474395],\n",
              "       [2.7741625],\n",
              "       [2.6062627],\n",
              "       [3.451293 ],\n",
              "       [2.892212 ],\n",
              "       [2.686903 ],\n",
              "       [2.6578252],\n",
              "       [2.5641637],\n",
              "       [2.8107288],\n",
              "       [3.0276725],\n",
              "       [2.825677 ],\n",
              "       [2.427061 ],\n",
              "       [2.2531714],\n",
              "       [2.7134442],\n",
              "       [2.4624314],\n",
              "       [2.6034772],\n",
              "       [3.148757 ],\n",
              "       [2.5555398],\n",
              "       [3.1058226],\n",
              "       [2.6476555],\n",
              "       [2.5111024],\n",
              "       [2.8174977],\n",
              "       [2.332206 ],\n",
              "       [2.7553036],\n",
              "       [2.980203 ],\n",
              "       [2.619629 ],\n",
              "       [2.4984257],\n",
              "       [2.7184324],\n",
              "       [3.0021832],\n",
              "       [3.2281752],\n",
              "       [2.803435 ],\n",
              "       [2.8399186],\n",
              "       [2.624767 ],\n",
              "       [2.5185375],\n",
              "       [2.548331 ],\n",
              "       [2.8947225],\n",
              "       [3.2629306],\n",
              "       [3.2934976],\n",
              "       [2.4229276],\n",
              "       [2.5384412],\n",
              "       [3.0387752],\n",
              "       [2.6724477],\n",
              "       [2.9183073],\n",
              "       [2.778858 ],\n",
              "       [2.918041 ],\n",
              "       [2.6661167],\n",
              "       [2.6277475],\n",
              "       [2.633243 ],\n",
              "       [2.8408473],\n",
              "       [2.8613126],\n",
              "       [2.7525806],\n",
              "       [2.8715816],\n",
              "       [3.1184387],\n",
              "       [2.3573341],\n",
              "       [2.4555297],\n",
              "       [2.7072427],\n",
              "       [2.732114 ],\n",
              "       [2.3783045],\n",
              "       [2.3688037],\n",
              "       [2.089611 ],\n",
              "       [2.9693148],\n",
              "       [2.904066 ],\n",
              "       [2.4266667],\n",
              "       [2.0513723],\n",
              "       [2.7640016],\n",
              "       [2.276318 ],\n",
              "       [3.3498373],\n",
              "       [2.793652 ],\n",
              "       [2.5111673],\n",
              "       [2.8775373],\n",
              "       [2.4054499],\n",
              "       [2.8293395],\n",
              "       [2.8032646],\n",
              "       [2.8104432],\n",
              "       [1.9039123],\n",
              "       [2.8729064],\n",
              "       [2.869101 ],\n",
              "       [2.8638022],\n",
              "       [3.0387104],\n",
              "       [2.6819603],\n",
              "       [2.3084416],\n",
              "       [3.0662966],\n",
              "       [2.8233237],\n",
              "       [2.5555882],\n",
              "       [3.1179924],\n",
              "       [2.4618623],\n",
              "       [2.8209782],\n",
              "       [3.1157937],\n",
              "       [2.6593223],\n",
              "       [2.9641917],\n",
              "       [2.5344853],\n",
              "       [2.6089506],\n",
              "       [2.5575507],\n",
              "       [2.704411 ],\n",
              "       [2.587078 ],\n",
              "       [2.794088 ],\n",
              "       [2.5783396],\n",
              "       [2.7376535],\n",
              "       [2.7392828],\n",
              "       [2.698345 ],\n",
              "       [2.6733718],\n",
              "       [2.5008953],\n",
              "       [2.578778 ],\n",
              "       [2.5962753],\n",
              "       [2.521731 ],\n",
              "       [2.7855506],\n",
              "       [2.2557352],\n",
              "       [2.4278839],\n",
              "       [2.2783272],\n",
              "       [2.4559517],\n",
              "       [3.2096765],\n",
              "       [2.7847338],\n",
              "       [2.8379056],\n",
              "       [2.316172 ],\n",
              "       [2.6910446],\n",
              "       [2.6178675],\n",
              "       [2.6717477],\n",
              "       [2.5791383],\n",
              "       [2.5538843],\n",
              "       [3.0819798],\n",
              "       [2.7119498],\n",
              "       [2.2634814],\n",
              "       [2.90181  ],\n",
              "       [2.4950829],\n",
              "       [2.641101 ],\n",
              "       [2.7717862],\n",
              "       [2.6454577],\n",
              "       [2.9878702],\n",
              "       [3.3215208],\n",
              "       [2.3855648],\n",
              "       [2.6117673],\n",
              "       [2.9462087],\n",
              "       [2.6122618],\n",
              "       [2.2577195],\n",
              "       [2.883912 ],\n",
              "       [2.5452023],\n",
              "       [2.5608082],\n",
              "       [2.7541602],\n",
              "       [2.369789 ],\n",
              "       [2.7784948],\n",
              "       [2.4758797],\n",
              "       [2.510447 ],\n",
              "       [3.355352 ],\n",
              "       [2.8860588],\n",
              "       [2.8418884],\n",
              "       [2.8477712],\n",
              "       [3.3771317],\n",
              "       [2.472169 ],\n",
              "       [2.7531433],\n",
              "       [2.605    ],\n",
              "       [2.5821605],\n",
              "       [2.8734965],\n",
              "       [2.6014538],\n",
              "       [2.705418 ],\n",
              "       [2.8554235],\n",
              "       [3.083405 ],\n",
              "       [2.4392786],\n",
              "       [2.290602 ],\n",
              "       [2.8293173],\n",
              "       [2.6048317],\n",
              "       [2.810638 ],\n",
              "       [2.5135832],\n",
              "       [2.7499099],\n",
              "       [2.8022416],\n",
              "       [2.6260307],\n",
              "       [2.194549 ],\n",
              "       [3.064596 ],\n",
              "       [2.8559186],\n",
              "       [2.8364964],\n",
              "       [2.7086792],\n",
              "       [2.7389998],\n",
              "       [2.7202084],\n",
              "       [2.2338812],\n",
              "       [2.6516573],\n",
              "       [2.8287754],\n",
              "       [2.9615178],\n",
              "       [2.507816 ],\n",
              "       [2.458459 ],\n",
              "       [2.6728144],\n",
              "       [2.9731452],\n",
              "       [3.688261 ],\n",
              "       [2.676372 ],\n",
              "       [2.7867136],\n",
              "       [2.6432164],\n",
              "       [2.7453408],\n",
              "       [3.0521955],\n",
              "       [2.608937 ],\n",
              "       [2.4015803],\n",
              "       [2.503034 ],\n",
              "       [2.3650563],\n",
              "       [3.0922294],\n",
              "       [3.4085202],\n",
              "       [2.6667717],\n",
              "       [2.6391385],\n",
              "       [2.9404545],\n",
              "       [2.5585995],\n",
              "       [2.6389923],\n",
              "       [2.6822186],\n",
              "       [2.7803783],\n",
              "       [3.0173554],\n",
              "       [2.6915941],\n",
              "       [2.9597611],\n",
              "       [2.5967956],\n",
              "       [2.5349207],\n",
              "       [3.0106997],\n",
              "       [2.8947253],\n",
              "       [3.1597393],\n",
              "       [3.3372068],\n",
              "       [2.8808131],\n",
              "       [3.5409184],\n",
              "       [2.8622158],\n",
              "       [3.1686678],\n",
              "       [2.2599473],\n",
              "       [2.0834424],\n",
              "       [2.965537 ],\n",
              "       [2.9153893],\n",
              "       [2.8739874],\n",
              "       [2.6429484],\n",
              "       [2.555745 ],\n",
              "       [2.332135 ],\n",
              "       [2.595708 ],\n",
              "       [2.9240077],\n",
              "       [2.9151993],\n",
              "       [2.5805829],\n",
              "       [2.8704948],\n",
              "       [2.6056423],\n",
              "       [2.7754087],\n",
              "       [2.6085515],\n",
              "       [2.3706026],\n",
              "       [2.6392558],\n",
              "       [2.8187373],\n",
              "       [2.5876245],\n",
              "       [2.2456908],\n",
              "       [2.585571 ],\n",
              "       [2.7749474],\n",
              "       [2.8585713],\n",
              "       [3.1631856],\n",
              "       [2.9611754],\n",
              "       [3.0491083],\n",
              "       [2.7955937],\n",
              "       [2.878123 ],\n",
              "       [2.6674361],\n",
              "       [2.6650617],\n",
              "       [2.4830008],\n",
              "       [2.523881 ],\n",
              "       [3.132162 ],\n",
              "       [3.361569 ],\n",
              "       [2.9285839],\n",
              "       [2.6749885],\n",
              "       [3.2739816],\n",
              "       [2.7712011],\n",
              "       [2.586125 ],\n",
              "       [3.2841132],\n",
              "       [2.5986955],\n",
              "       [2.4274063],\n",
              "       [2.625164 ],\n",
              "       [2.6102407],\n",
              "       [2.7953153],\n",
              "       [2.9191492],\n",
              "       [2.5615947],\n",
              "       [2.538684 ],\n",
              "       [3.3738885],\n",
              "       [2.9078538],\n",
              "       [2.8454864],\n",
              "       [2.9563732],\n",
              "       [2.7837448],\n",
              "       [2.7864885],\n",
              "       [2.7480402],\n",
              "       [2.693435 ],\n",
              "       [2.5564415],\n",
              "       [2.8037157],\n",
              "       [2.9007783],\n",
              "       [2.651693 ],\n",
              "       [3.090414 ],\n",
              "       [2.981438 ],\n",
              "       [2.5888865],\n",
              "       [2.4216635],\n",
              "       [2.8755727],\n",
              "       [2.4931345],\n",
              "       [2.6555512],\n",
              "       [3.0525298],\n",
              "       [2.7183042],\n",
              "       [2.4015112],\n",
              "       [2.5984645],\n",
              "       [2.2386878],\n",
              "       [2.706569 ],\n",
              "       [2.7612994],\n",
              "       [2.606718 ],\n",
              "       [2.6620593],\n",
              "       [2.5744665],\n",
              "       [2.508102 ],\n",
              "       [2.489939 ],\n",
              "       [2.6347427],\n",
              "       [3.2444777],\n",
              "       [2.9073446],\n",
              "       [2.7210896],\n",
              "       [2.301129 ],\n",
              "       [2.9725156],\n",
              "       [2.5744915],\n",
              "       [2.8120012],\n",
              "       [3.0479305],\n",
              "       [2.6240985],\n",
              "       [2.4714236],\n",
              "       [2.5891993],\n",
              "       [2.8615148],\n",
              "       [2.9410124],\n",
              "       [2.291653 ],\n",
              "       [2.5281417],\n",
              "       [2.4940507],\n",
              "       [2.915683 ],\n",
              "       [2.5486796],\n",
              "       [2.833391 ],\n",
              "       [2.6218493],\n",
              "       [2.901469 ],\n",
              "       [3.0942097],\n",
              "       [2.6968977],\n",
              "       [2.3664103],\n",
              "       [2.5116653],\n",
              "       [2.8086102],\n",
              "       [2.4082918],\n",
              "       [2.7942142],\n",
              "       [2.5194907],\n",
              "       [3.0132942],\n",
              "       [2.7836444],\n",
              "       [2.4057508],\n",
              "       [2.6316996],\n",
              "       [2.8717508],\n",
              "       [2.6743731],\n",
              "       [2.4599907],\n",
              "       [2.8353186],\n",
              "       [2.8571   ],\n",
              "       [2.4673653],\n",
              "       [2.871583 ],\n",
              "       [3.0092423],\n",
              "       [2.7086856],\n",
              "       [2.4893794],\n",
              "       [3.1347237],\n",
              "       [2.4162078],\n",
              "       [2.901382 ],\n",
              "       [2.011616 ],\n",
              "       [2.2620184],\n",
              "       [2.4915223],\n",
              "       [2.7733939],\n",
              "       [2.9932194],\n",
              "       [2.6680303],\n",
              "       [2.6597648],\n",
              "       [2.5565343],\n",
              "       [2.823377 ],\n",
              "       [2.597855 ],\n",
              "       [2.9437437],\n",
              "       [2.6627047],\n",
              "       [3.218563 ],\n",
              "       [2.605701 ],\n",
              "       [2.683949 ],\n",
              "       [2.9276366],\n",
              "       [2.751028 ],\n",
              "       [2.8747346],\n",
              "       [2.8775597],\n",
              "       [2.5413852],\n",
              "       [2.8859978],\n",
              "       [3.0531654],\n",
              "       [2.663219 ],\n",
              "       [2.516701 ],\n",
              "       [3.0065818],\n",
              "       [3.8411689],\n",
              "       [2.8217988],\n",
              "       [2.5649016],\n",
              "       [2.631814 ],\n",
              "       [2.6403468],\n",
              "       [2.378844 ],\n",
              "       [2.5441356],\n",
              "       [3.1163836],\n",
              "       [2.665228 ],\n",
              "       [2.827002 ],\n",
              "       [2.68661  ],\n",
              "       [2.6312582],\n",
              "       [2.970605 ],\n",
              "       [2.5789287],\n",
              "       [2.736833 ],\n",
              "       [2.4735293],\n",
              "       [2.4269838],\n",
              "       [2.485038 ],\n",
              "       [2.628931 ],\n",
              "       [2.6468256],\n",
              "       [2.5214381],\n",
              "       [2.7594907],\n",
              "       [2.8589427],\n",
              "       [2.8638878],\n",
              "       [2.620726 ],\n",
              "       [2.8669624],\n",
              "       [4.0690613],\n",
              "       [2.5966873],\n",
              "       [2.5886652],\n",
              "       [2.8196845],\n",
              "       [2.549512 ],\n",
              "       [2.7943587],\n",
              "       [3.1160674],\n",
              "       [2.557187 ],\n",
              "       [2.910048 ],\n",
              "       [3.0339363],\n",
              "       [2.3446825],\n",
              "       [2.8216782],\n",
              "       [2.8096466],\n",
              "       [2.674192 ],\n",
              "       [2.3064911],\n",
              "       [2.9445393],\n",
              "       [2.739809 ],\n",
              "       [2.653955 ],\n",
              "       [3.0719028],\n",
              "       [2.4834945],\n",
              "       [2.4779139],\n",
              "       [3.137388 ],\n",
              "       [2.286106 ],\n",
              "       [2.242761 ],\n",
              "       [2.818758 ],\n",
              "       [2.5318031],\n",
              "       [2.8783026],\n",
              "       [3.2694387],\n",
              "       [2.708621 ],\n",
              "       [2.850532 ],\n",
              "       [2.5284414],\n",
              "       [2.8818946],\n",
              "       [3.137055 ],\n",
              "       [2.7527504],\n",
              "       [2.9387193],\n",
              "       [2.3821084],\n",
              "       [2.6461568],\n",
              "       [2.6834867],\n",
              "       [2.6925292],\n",
              "       [2.516516 ],\n",
              "       [2.4284513],\n",
              "       [2.5295806],\n",
              "       [2.6732621],\n",
              "       [3.072885 ],\n",
              "       [2.9709415],\n",
              "       [2.7271385],\n",
              "       [2.558833 ],\n",
              "       [2.5835786],\n",
              "       [2.9962173],\n",
              "       [3.8259506],\n",
              "       [2.4225364],\n",
              "       [3.181439 ],\n",
              "       [2.971241 ],\n",
              "       [2.745158 ],\n",
              "       [2.4086561],\n",
              "       [2.903615 ],\n",
              "       [2.5856462],\n",
              "       [2.7307696],\n",
              "       [2.8465676],\n",
              "       [2.1308825],\n",
              "       [2.8710392],\n",
              "       [3.0405607],\n",
              "       [2.744782 ],\n",
              "       [3.0884204],\n",
              "       [2.7091227],\n",
              "       [2.1286762],\n",
              "       [2.8041234],\n",
              "       [2.3882136],\n",
              "       [2.9887273],\n",
              "       [2.8259869],\n",
              "       [3.1450405],\n",
              "       [2.3815355],\n",
              "       [2.4914827],\n",
              "       [2.9239655],\n",
              "       [2.6238027],\n",
              "       [2.9108393],\n",
              "       [2.654759 ],\n",
              "       [2.595474 ],\n",
              "       [3.0366051],\n",
              "       [2.5701234],\n",
              "       [2.8281322],\n",
              "       [2.8835044],\n",
              "       [2.818381 ],\n",
              "       [2.6734028],\n",
              "       [2.4903383],\n",
              "       [2.319672 ],\n",
              "       [2.5427246],\n",
              "       [2.5773306],\n",
              "       [2.727192 ],\n",
              "       [2.5709825],\n",
              "       [2.7432785],\n",
              "       [2.9727278],\n",
              "       [2.9176888],\n",
              "       [2.8548071],\n",
              "       [2.694457 ],\n",
              "       [2.7645874],\n",
              "       [2.533442 ],\n",
              "       [2.631458 ],\n",
              "       [2.6908145],\n",
              "       [2.9103281],\n",
              "       [2.8533447],\n",
              "       [2.8439257],\n",
              "       [2.6505868],\n",
              "       [2.38439  ],\n",
              "       [2.660418 ],\n",
              "       [2.87953  ],\n",
              "       [2.4146569],\n",
              "       [2.932457 ],\n",
              "       [3.12307  ],\n",
              "       [2.2929473],\n",
              "       [2.8083036],\n",
              "       [2.521348 ],\n",
              "       [2.4875286],\n",
              "       [3.3079739],\n",
              "       [2.492829 ],\n",
              "       [2.4780858],\n",
              "       [2.5965953],\n",
              "       [3.1956139],\n",
              "       [2.8694432],\n",
              "       [2.5661824],\n",
              "       [2.7733161],\n",
              "       [3.5958643],\n",
              "       [2.6722713],\n",
              "       [3.2240424],\n",
              "       [2.7672818],\n",
              "       [2.4836931],\n",
              "       [3.6448362]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate vocabulary prediction accuracy"
      ],
      "metadata": {
        "id": "Mr4RhOIp_rr0"
      },
      "id": "Mr4RhOIp_rr0"
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list = []\n",
        "for value in prediction:\n",
        "  pre_list.append(value[0])"
      ],
      "metadata": {
        "id": "LLLz2sCz6EnH"
      },
      "id": "LLLz2sCz6EnH",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_range(Ytrue, Ypred):\n",
        "    accurate_range=0\n",
        "    for i in range(len(Ytrue)):\n",
        "        if abs(Ytrue[i] - Ypred[i])<=0.5:\n",
        "            accurate_range+=1\n",
        "    return accurate_range/len(Ytrue)"
      ],
      "metadata": {
        "id": "NX7aSlwCF-3Z"
      },
      "id": "NX7aSlwCF-3Z",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy = accuracy_range(pre_list, list(test_data['vocabulary']))\n",
        "val_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrI3jhm65X7x",
        "outputId": "6a55109b-4d64-4b77-821e-7f62e1d4f176"
      },
      "id": "PrI3jhm65X7x",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5006385696040868"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def result(predictions):\n",
        "    result_list=[]\n",
        "    for pred in predictions:\n",
        "        result = pred // 0.5 * 0.5\n",
        "        if (pred - result) > 0.25:\n",
        "            result += 0.5\n",
        "        if result < 1.0:\n",
        "            result = 1.0\n",
        "        if result > 5.0:\n",
        "            result = 5.0\n",
        "        result_list.append(result)\n",
        "    return result_list\n",
        "\n",
        "def accuracy(Ytrue, Ypred):\n",
        "    accurate = 0\n",
        "    for i in range(len(Ytrue)):\n",
        "        if Ytrue[i] == Ypred[i]:\n",
        "            accurate += 1\n",
        "    return accurate / len(Ytrue)"
      ],
      "metadata": {
        "id": "Rnk9tqV_6uZV"
      },
      "id": "Rnk9tqV_6uZV",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list_2 = result(pre_list)"
      ],
      "metadata": {
        "id": "A2ws_RJY6vZK"
      },
      "id": "A2ws_RJY6vZK",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy_2 = accuracy(list(test_data['vocabulary']), pre_list_2)\n",
        "val_accuracy_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl_Gmj0n67dz",
        "outputId": "0f8e8007-1168-473e-b73a-8341d26f604c"
      },
      "id": "Hl_Gmj0n67dz",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22094508301404853"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model for cohesion using vocabulary"
      ],
      "metadata": {
        "id": "Gx4gjkYqB1M3"
      },
      "id": "Gx4gjkYqB1M3"
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "number_epochs = 30\n",
        "batch_size = 256\n",
        "label_name = \"cohesion\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "model_lr_cohesion = create_model_linear(learning_rate, my_new_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "mse_train_lr_cohesion, mse_val_lr_cohesion = train_model(model_lr_cohesion, train_data, number_epochs, batch_size, label_name)\n",
        "#train_history = train_model(model_lr, train_data, number_epochs, batch_size, label_name)\n",
        "plot_the_loss_curve(mse_train_lr_cohesion, mse_val_lr_cohesion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n2YCGivSGgUb",
        "outputId": "e9ce2adc-2c3e-461d-afb3-081cab07d0f4"
      },
      "id": "n2YCGivSGgUb",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/10 [==>...........................] - ETA: 14s - loss: 4298.7373 - mean_squared_error: 4298.7373 - accuracy: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 3s 104ms/step - loss: 6236.1001 - mean_squared_error: 6236.1001 - accuracy: 7.9936e-04 - val_loss: 4.3810 - val_mean_squared_error: 4.3810 - val_accuracy: 0.0032\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 3.2628 - mean_squared_error: 3.2628 - accuracy: 0.0012 - val_loss: 3.3103 - val_mean_squared_error: 3.3103 - val_accuracy: 0.0032\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 67.3727 - mean_squared_error: 67.3727 - accuracy: 0.0012 - val_loss: 23.7892 - val_mean_squared_error: 23.7892 - val_accuracy: 0.0032\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 86.8819 - mean_squared_error: 86.8819 - accuracy: 0.0012 - val_loss: 52.3277 - val_mean_squared_error: 52.3277 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 44.3938 - mean_squared_error: 44.3938 - accuracy: 0.0016 - val_loss: 227.0280 - val_mean_squared_error: 227.0280 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 70.1851 - mean_squared_error: 70.1851 - accuracy: 7.9936e-04 - val_loss: 12.4196 - val_mean_squared_error: 12.4196 - val_accuracy: 0.0032\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 73.9417 - mean_squared_error: 73.9417 - accuracy: 3.9968e-04 - val_loss: 6.2529 - val_mean_squared_error: 6.2529 - val_accuracy: 0.0032\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.8209 - mean_squared_error: 1.8209 - accuracy: 0.0012 - val_loss: 2.4994 - val_mean_squared_error: 2.4994 - val_accuracy: 0.0032\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 47.8143 - mean_squared_error: 47.8143 - accuracy: 7.9936e-04 - val_loss: 0.8791 - val_mean_squared_error: 0.8791 - val_accuracy: 0.0016\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7349 - mean_squared_error: 0.7349 - accuracy: 0.0012 - val_loss: 0.6767 - val_mean_squared_error: 0.6767 - val_accuracy: 0.0016\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 26.2276 - mean_squared_error: 26.2276 - accuracy: 0.0016 - val_loss: 1.4715 - val_mean_squared_error: 1.4715 - val_accuracy: 0.0032\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7253 - mean_squared_error: 0.7253 - accuracy: 0.0016 - val_loss: 0.7166 - val_mean_squared_error: 0.7166 - val_accuracy: 0.0032\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 8.0457 - mean_squared_error: 8.0457 - accuracy: 0.0012 - val_loss: 2.9746 - val_mean_squared_error: 2.9746 - val_accuracy: 0.0032\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8518 - mean_squared_error: 0.8518 - accuracy: 0.0016 - val_loss: 0.5301 - val_mean_squared_error: 0.5301 - val_accuracy: 0.0032\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 4.5120 - mean_squared_error: 4.5120 - accuracy: 0.0016 - val_loss: 1.2387 - val_mean_squared_error: 1.2387 - val_accuracy: 0.0032\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2887 - mean_squared_error: 1.2887 - accuracy: 0.0016 - val_loss: 3.9573 - val_mean_squared_error: 3.9573 - val_accuracy: 0.0016\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.9040 - mean_squared_error: 1.9040 - accuracy: 0.0016 - val_loss: 0.8848 - val_mean_squared_error: 0.8848 - val_accuracy: 0.0032\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 3.1545 - mean_squared_error: 3.1545 - accuracy: 0.0016 - val_loss: 0.7765 - val_mean_squared_error: 0.7765 - val_accuracy: 0.0032\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.0813 - mean_squared_error: 1.0813 - accuracy: 0.0016 - val_loss: 1.5119 - val_mean_squared_error: 1.5119 - val_accuracy: 0.0032\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3246 - mean_squared_error: 1.3246 - accuracy: 0.0016 - val_loss: 1.1087 - val_mean_squared_error: 1.1087 - val_accuracy: 0.0032\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7582 - mean_squared_error: 1.7582 - accuracy: 0.0016 - val_loss: 0.7138 - val_mean_squared_error: 0.7138 - val_accuracy: 0.0032\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.9271 - mean_squared_error: 0.9271 - accuracy: 0.0016 - val_loss: 1.0224 - val_mean_squared_error: 1.0224 - val_accuracy: 0.0032\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.0139 - mean_squared_error: 1.0139 - accuracy: 0.0016 - val_loss: 0.7688 - val_mean_squared_error: 0.7688 - val_accuracy: 0.0032\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.1330 - mean_squared_error: 1.1330 - accuracy: 0.0016 - val_loss: 0.5609 - val_mean_squared_error: 0.5609 - val_accuracy: 0.0032\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8813 - mean_squared_error: 0.8813 - accuracy: 0.0016 - val_loss: 0.7221 - val_mean_squared_error: 0.7221 - val_accuracy: 0.0032\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7845 - mean_squared_error: 0.7845 - accuracy: 0.0016 - val_loss: 0.9374 - val_mean_squared_error: 0.9374 - val_accuracy: 0.0032\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.2217 - mean_squared_error: 1.2217 - accuracy: 0.0016 - val_loss: 0.4556 - val_mean_squared_error: 0.4556 - val_accuracy: 0.0032\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6846 - mean_squared_error: 0.6846 - accuracy: 0.0016 - val_loss: 0.6568 - val_mean_squared_error: 0.6568 - val_accuracy: 0.0032\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.7282 - mean_squared_error: 0.7282 - accuracy: 0.0016 - val_loss: 0.6423 - val_mean_squared_error: 0.6423 - val_accuracy: 0.0032\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9222 - mean_squared_error: 0.9222 - accuracy: 0.0016 - val_loss: 0.5744 - val_mean_squared_error: 0.5744 - val_accuracy: 0.0032\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using test data to get the estimation"
      ],
      "metadata": {
        "id": "tbxZGEY2mmbW"
      },
      "id": "tbxZGEY2mmbW"
    },
    {
      "cell_type": "code",
      "source": [
        "test_data2 = test_data\n",
        "test_data2.pop(\"vocabulary\")\n",
        "test_data2[\"vocabulary\"] = pre_list\n",
        "test_features_cohesion = {name:np.array(value) for name, value in test_data2.items()}\n",
        "\n",
        "test_label_cohesion = np.array(test_features_cohesion.pop(\"cohesion\"))# isolate the label\n",
        "\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "result_cohesion = model_lr_cohesion.evaluate(x=test_features_cohesion, y=test_label_cohesion, batch_size=batch_size)\n",
        "\n",
        "for item in zip(model_lr_cohesion.metrics_names, result_cohesion):\n",
        "  print (item[0], item[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00416982-f239-4b63-9c73-70e6b04edff4",
        "id": "uEPeNAAKnFGC"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5432 - mean_squared_error: 0.5432 - accuracy: 0.0051\n",
            "loss 0.543190062046051\n",
            "mean_squared_error 0.543190062046051\n",
            "accuracy 0.0051085567101836205\n"
          ]
        }
      ],
      "id": "uEPeNAAKnFGC"
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_cohesion = model_lr_cohesion.predict(test_features_cohesion)\n",
        "prediction_cohesion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fbc631c-cae8-4f72-8f97-e311899c6e57",
        "id": "SdWLPbQpnFGC"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.310013  ],\n",
              "       [3.4821384 ],\n",
              "       [2.708336  ],\n",
              "       [3.6739066 ],\n",
              "       [3.5435877 ],\n",
              "       [3.8221598 ],\n",
              "       [3.2621899 ],\n",
              "       [3.53032   ],\n",
              "       [3.4127808 ],\n",
              "       [4.0623765 ],\n",
              "       [3.4402118 ],\n",
              "       [3.4770977 ],\n",
              "       [3.5019324 ],\n",
              "       [3.4143763 ],\n",
              "       [3.7014532 ],\n",
              "       [3.807831  ],\n",
              "       [3.7908146 ],\n",
              "       [4.210506  ],\n",
              "       [2.3957403 ],\n",
              "       [2.9953313 ],\n",
              "       [6.3329015 ],\n",
              "       [3.992249  ],\n",
              "       [4.1386642 ],\n",
              "       [3.7675486 ],\n",
              "       [3.7647915 ],\n",
              "       [3.6111066 ],\n",
              "       [4.10657   ],\n",
              "       [3.3236928 ],\n",
              "       [3.827556  ],\n",
              "       [3.334388  ],\n",
              "       [2.9486074 ],\n",
              "       [2.776396  ],\n",
              "       [3.9000635 ],\n",
              "       [4.455518  ],\n",
              "       [3.5845947 ],\n",
              "       [3.709329  ],\n",
              "       [3.5851817 ],\n",
              "       [3.9639394 ],\n",
              "       [3.6320295 ],\n",
              "       [2.1543527 ],\n",
              "       [3.854756  ],\n",
              "       [3.5197318 ],\n",
              "       [3.6125033 ],\n",
              "       [3.8975995 ],\n",
              "       [3.1558185 ],\n",
              "       [3.5706682 ],\n",
              "       [3.6468108 ],\n",
              "       [3.808738  ],\n",
              "       [3.442121  ],\n",
              "       [3.531978  ],\n",
              "       [2.6864638 ],\n",
              "       [3.5585883 ],\n",
              "       [3.3691401 ],\n",
              "       [3.5924883 ],\n",
              "       [3.282442  ],\n",
              "       [3.522475  ],\n",
              "       [3.7922876 ],\n",
              "       [3.9956028 ],\n",
              "       [3.8225722 ],\n",
              "       [3.8202314 ],\n",
              "       [3.5779998 ],\n",
              "       [4.524892  ],\n",
              "       [2.4440317 ],\n",
              "       [3.7444925 ],\n",
              "       [3.9992511 ],\n",
              "       [3.9636114 ],\n",
              "       [2.2447853 ],\n",
              "       [3.8948092 ],\n",
              "       [3.2250395 ],\n",
              "       [3.9351838 ],\n",
              "       [2.7853096 ],\n",
              "       [4.015457  ],\n",
              "       [3.3334873 ],\n",
              "       [3.1442654 ],\n",
              "       [4.1184335 ],\n",
              "       [3.9148319 ],\n",
              "       [3.9374135 ],\n",
              "       [4.7603292 ],\n",
              "       [3.7338605 ],\n",
              "       [2.2830622 ],\n",
              "       [3.082235  ],\n",
              "       [3.2516184 ],\n",
              "       [3.197878  ],\n",
              "       [3.7058463 ],\n",
              "       [3.9002671 ],\n",
              "       [3.1728306 ],\n",
              "       [4.0630846 ],\n",
              "       [3.759543  ],\n",
              "       [3.5566995 ],\n",
              "       [2.8614447 ],\n",
              "       [3.9851933 ],\n",
              "       [3.869987  ],\n",
              "       [3.5880415 ],\n",
              "       [2.652021  ],\n",
              "       [3.5209305 ],\n",
              "       [3.5677767 ],\n",
              "       [3.0363781 ],\n",
              "       [4.551962  ],\n",
              "       [3.8619623 ],\n",
              "       [3.1018906 ],\n",
              "       [3.4801443 ],\n",
              "       [3.511733  ],\n",
              "       [2.769926  ],\n",
              "       [3.4789085 ],\n",
              "       [3.0626771 ],\n",
              "       [4.099502  ],\n",
              "       [3.3715534 ],\n",
              "       [3.756629  ],\n",
              "       [3.6799934 ],\n",
              "       [2.9762793 ],\n",
              "       [4.294562  ],\n",
              "       [3.7165477 ],\n",
              "       [3.7221208 ],\n",
              "       [3.455682  ],\n",
              "       [3.3485882 ],\n",
              "       [3.2493029 ],\n",
              "       [3.8758059 ],\n",
              "       [4.0045443 ],\n",
              "       [3.1854844 ],\n",
              "       [2.9631467 ],\n",
              "       [3.0078015 ],\n",
              "       [4.0135922 ],\n",
              "       [3.5221086 ],\n",
              "       [1.5159044 ],\n",
              "       [3.8189852 ],\n",
              "       [3.012621  ],\n",
              "       [3.919733  ],\n",
              "       [3.8629293 ],\n",
              "       [3.2224321 ],\n",
              "       [3.8847194 ],\n",
              "       [3.052824  ],\n",
              "       [2.881656  ],\n",
              "       [3.9960651 ],\n",
              "       [2.778005  ],\n",
              "       [3.8359232 ],\n",
              "       [3.9614182 ],\n",
              "       [3.3090332 ],\n",
              "       [3.5778513 ],\n",
              "       [3.450717  ],\n",
              "       [3.9036717 ],\n",
              "       [2.3965952 ],\n",
              "       [4.1802    ],\n",
              "       [3.5685847 ],\n",
              "       [3.9688225 ],\n",
              "       [3.7122574 ],\n",
              "       [3.9613886 ],\n",
              "       [3.4785194 ],\n",
              "       [3.59338   ],\n",
              "       [3.924237  ],\n",
              "       [3.3225856 ],\n",
              "       [3.171552  ],\n",
              "       [3.4164724 ],\n",
              "       [3.7139595 ],\n",
              "       [2.8494089 ],\n",
              "       [3.6906621 ],\n",
              "       [2.933052  ],\n",
              "       [2.8259666 ],\n",
              "       [3.2068307 ],\n",
              "       [3.199202  ],\n",
              "       [3.054213  ],\n",
              "       [4.1521544 ],\n",
              "       [3.739982  ],\n",
              "       [3.2830367 ],\n",
              "       [3.3070638 ],\n",
              "       [3.8259044 ],\n",
              "       [2.8012471 ],\n",
              "       [3.390891  ],\n",
              "       [4.0770674 ],\n",
              "       [3.4495862 ],\n",
              "       [3.413595  ],\n",
              "       [3.8129034 ],\n",
              "       [3.6622963 ],\n",
              "       [3.4006333 ],\n",
              "       [3.2390733 ],\n",
              "       [3.5889196 ],\n",
              "       [3.2420514 ],\n",
              "       [2.6429358 ],\n",
              "       [3.752162  ],\n",
              "       [3.8103244 ],\n",
              "       [3.8705559 ],\n",
              "       [3.2920341 ],\n",
              "       [3.8037963 ],\n",
              "       [3.7741497 ],\n",
              "       [3.6291997 ],\n",
              "       [4.1039925 ],\n",
              "       [3.556724  ],\n",
              "       [3.476511  ],\n",
              "       [4.101479  ],\n",
              "       [3.2244046 ],\n",
              "       [3.4279926 ],\n",
              "       [2.5835228 ],\n",
              "       [2.6805413 ],\n",
              "       [4.5147653 ],\n",
              "       [3.610024  ],\n",
              "       [3.682701  ],\n",
              "       [4.450293  ],\n",
              "       [5.059132  ],\n",
              "       [3.7234187 ],\n",
              "       [4.526876  ],\n",
              "       [3.5977054 ],\n",
              "       [3.551415  ],\n",
              "       [2.8307667 ],\n",
              "       [3.5913186 ],\n",
              "       [3.3300815 ],\n",
              "       [3.568677  ],\n",
              "       [4.313777  ],\n",
              "       [3.561864  ],\n",
              "       [4.172469  ],\n",
              "       [3.2481835 ],\n",
              "       [2.5767493 ],\n",
              "       [1.161475  ],\n",
              "       [3.3624198 ],\n",
              "       [4.6048446 ],\n",
              "       [3.164259  ],\n",
              "       [2.8204257 ],\n",
              "       [3.80711   ],\n",
              "       [4.000575  ],\n",
              "       [1.1989398 ],\n",
              "       [3.9408386 ],\n",
              "       [4.2516623 ],\n",
              "       [4.2814393 ],\n",
              "       [4.2187037 ],\n",
              "       [4.053107  ],\n",
              "       [4.371549  ],\n",
              "       [3.5712483 ],\n",
              "       [3.6258743 ],\n",
              "       [3.2457485 ],\n",
              "       [2.7980971 ],\n",
              "       [3.3068745 ],\n",
              "       [3.4763439 ],\n",
              "       [3.426083  ],\n",
              "       [3.9624336 ],\n",
              "       [4.0560904 ],\n",
              "       [3.353731  ],\n",
              "       [2.600028  ],\n",
              "       [3.3484569 ],\n",
              "       [4.119196  ],\n",
              "       [2.8637123 ],\n",
              "       [3.7394633 ],\n",
              "       [3.600405  ],\n",
              "       [3.4821308 ],\n",
              "       [3.586484  ],\n",
              "       [4.2190733 ],\n",
              "       [3.6417174 ],\n",
              "       [3.930202  ],\n",
              "       [3.8648143 ],\n",
              "       [3.5509715 ],\n",
              "       [3.5441623 ],\n",
              "       [3.2006888 ],\n",
              "       [3.6917734 ],\n",
              "       [3.2797298 ],\n",
              "       [3.637603  ],\n",
              "       [3.9813902 ],\n",
              "       [3.2435071 ],\n",
              "       [3.8477259 ],\n",
              "       [4.5785356 ],\n",
              "       [3.6152592 ],\n",
              "       [3.9650588 ],\n",
              "       [4.27628   ],\n",
              "       [4.121204  ],\n",
              "       [3.8966112 ],\n",
              "       [3.6462238 ],\n",
              "       [3.5276463 ],\n",
              "       [3.849159  ],\n",
              "       [4.0244966 ],\n",
              "       [3.9500833 ],\n",
              "       [3.479531  ],\n",
              "       [3.2005954 ],\n",
              "       [3.6444643 ],\n",
              "       [4.1425796 ],\n",
              "       [3.4637332 ],\n",
              "       [3.3439095 ],\n",
              "       [2.1034303 ],\n",
              "       [3.306509  ],\n",
              "       [3.9646354 ],\n",
              "       [3.7124891 ],\n",
              "       [3.9551718 ],\n",
              "       [3.444347  ],\n",
              "       [3.039148  ],\n",
              "       [2.8558118 ],\n",
              "       [3.4144359 ],\n",
              "       [2.6919382 ],\n",
              "       [4.206007  ],\n",
              "       [3.8864036 ],\n",
              "       [3.9653673 ],\n",
              "       [3.1979492 ],\n",
              "       [3.1418712 ],\n",
              "       [3.287538  ],\n",
              "       [1.4949331 ],\n",
              "       [3.8075235 ],\n",
              "       [4.009074  ],\n",
              "       [3.464191  ],\n",
              "       [2.3466218 ],\n",
              "       [3.4739165 ],\n",
              "       [4.1390195 ],\n",
              "       [4.606522  ],\n",
              "       [3.7533748 ],\n",
              "       [3.5126395 ],\n",
              "       [3.3259094 ],\n",
              "       [3.460637  ],\n",
              "       [2.9070048 ],\n",
              "       [3.985159  ],\n",
              "       [3.1231854 ],\n",
              "       [3.7374074 ],\n",
              "       [3.6498797 ],\n",
              "       [3.734397  ],\n",
              "       [4.112918  ],\n",
              "       [2.840736  ],\n",
              "       [3.8777926 ],\n",
              "       [3.069425  ],\n",
              "       [3.6569824 ],\n",
              "       [3.722251  ],\n",
              "       [3.4882736 ],\n",
              "       [3.2836888 ],\n",
              "       [3.7146301 ],\n",
              "       [3.6503894 ],\n",
              "       [3.6722808 ],\n",
              "       [2.2736454 ],\n",
              "       [4.1310554 ],\n",
              "       [3.2149205 ],\n",
              "       [3.354278  ],\n",
              "       [3.7841363 ],\n",
              "       [3.789578  ],\n",
              "       [2.556219  ],\n",
              "       [3.4522672 ],\n",
              "       [1.0795233 ],\n",
              "       [4.3476896 ],\n",
              "       [3.911808  ],\n",
              "       [3.1472797 ],\n",
              "       [2.3846927 ],\n",
              "       [3.8134024 ],\n",
              "       [3.6358156 ],\n",
              "       [4.2477074 ],\n",
              "       [3.7925804 ],\n",
              "       [3.200766  ],\n",
              "       [4.0799747 ],\n",
              "       [3.7743921 ],\n",
              "       [3.254156  ],\n",
              "       [3.319213  ],\n",
              "       [3.8803    ],\n",
              "       [0.85878557],\n",
              "       [3.5684757 ],\n",
              "       [3.9460967 ],\n",
              "       [3.91124   ],\n",
              "       [4.268137  ],\n",
              "       [3.816133  ],\n",
              "       [3.4577968 ],\n",
              "       [4.094685  ],\n",
              "       [2.8374922 ],\n",
              "       [3.123257  ],\n",
              "       [4.2939787 ],\n",
              "       [3.29951   ],\n",
              "       [3.2829318 ],\n",
              "       [4.0706267 ],\n",
              "       [3.4675796 ],\n",
              "       [3.9801543 ],\n",
              "       [3.3632078 ],\n",
              "       [2.0616615 ],\n",
              "       [3.4272027 ],\n",
              "       [3.93947   ],\n",
              "       [3.1351678 ],\n",
              "       [3.121416  ],\n",
              "       [3.1974027 ],\n",
              "       [3.8780541 ],\n",
              "       [3.8539631 ],\n",
              "       [3.247338  ],\n",
              "       [3.4650652 ],\n",
              "       [2.942339  ],\n",
              "       [3.5063195 ],\n",
              "       [2.6664813 ],\n",
              "       [3.3756895 ],\n",
              "       [3.705388  ],\n",
              "       [2.9770784 ],\n",
              "       [3.4295616 ],\n",
              "       [2.3010216 ],\n",
              "       [3.11567   ],\n",
              "       [3.889107  ],\n",
              "       [3.089499  ],\n",
              "       [3.614632  ],\n",
              "       [2.8860347 ],\n",
              "       [3.4680443 ],\n",
              "       [3.4615903 ],\n",
              "       [3.3304584 ],\n",
              "       [3.058991  ],\n",
              "       [1.5685642 ],\n",
              "       [4.0230308 ],\n",
              "       [3.0940337 ],\n",
              "       [2.213961  ],\n",
              "       [3.5612268 ],\n",
              "       [2.4955542 ],\n",
              "       [3.6697807 ],\n",
              "       [3.6781478 ],\n",
              "       [3.6200988 ],\n",
              "       [3.984312  ],\n",
              "       [4.4770174 ],\n",
              "       [2.965754  ],\n",
              "       [3.684777  ],\n",
              "       [4.0995674 ],\n",
              "       [3.837047  ],\n",
              "       [3.2922046 ],\n",
              "       [4.3690157 ],\n",
              "       [2.9850652 ],\n",
              "       [3.163648  ],\n",
              "       [3.9971125 ],\n",
              "       [3.5607624 ],\n",
              "       [3.495459  ],\n",
              "       [3.3171873 ],\n",
              "       [3.3175855 ],\n",
              "       [4.2934504 ],\n",
              "       [3.8848855 ],\n",
              "       [4.0214624 ],\n",
              "       [3.3579366 ],\n",
              "       [4.6357117 ],\n",
              "       [3.4035935 ],\n",
              "       [3.8104596 ],\n",
              "       [2.6221824 ],\n",
              "       [3.5226018 ],\n",
              "       [3.8422108 ],\n",
              "       [3.4176445 ],\n",
              "       [3.5887609 ],\n",
              "       [3.066203  ],\n",
              "       [4.1269894 ],\n",
              "       [3.2649193 ],\n",
              "       [3.270325  ],\n",
              "       [3.7883902 ],\n",
              "       [3.1049013 ],\n",
              "       [3.6690187 ],\n",
              "       [3.238494  ],\n",
              "       [3.8159528 ],\n",
              "       [3.730811  ],\n",
              "       [3.4024882 ],\n",
              "       [1.5470836 ],\n",
              "       [3.982118  ],\n",
              "       [3.8015203 ],\n",
              "       [3.8527136 ],\n",
              "       [2.7011728 ],\n",
              "       [3.5547857 ],\n",
              "       [3.834312  ],\n",
              "       [3.246862  ],\n",
              "       [3.642569  ],\n",
              "       [3.3222866 ],\n",
              "       [3.9789414 ],\n",
              "       [3.393295  ],\n",
              "       [2.3220077 ],\n",
              "       [3.6989927 ],\n",
              "       [4.4636025 ],\n",
              "       [4.8062253 ],\n",
              "       [2.668145  ],\n",
              "       [3.137821  ],\n",
              "       [2.8908243 ],\n",
              "       [3.6749418 ],\n",
              "       [4.1687937 ],\n",
              "       [3.7471032 ],\n",
              "       [2.8859725 ],\n",
              "       [2.7797012 ],\n",
              "       [2.8924632 ],\n",
              "       [4.4961996 ],\n",
              "       [4.3588624 ],\n",
              "       [3.5010943 ],\n",
              "       [3.4188042 ],\n",
              "       [3.639821  ],\n",
              "       [3.74257   ],\n",
              "       [3.6282377 ],\n",
              "       [3.5972924 ],\n",
              "       [3.7307973 ],\n",
              "       [4.088649  ],\n",
              "       [3.581348  ],\n",
              "       [3.0722554 ],\n",
              "       [3.6647687 ],\n",
              "       [3.2358449 ],\n",
              "       [2.9744818 ],\n",
              "       [3.5608506 ],\n",
              "       [4.142165  ],\n",
              "       [4.043523  ],\n",
              "       [3.9839559 ],\n",
              "       [4.663706  ],\n",
              "       [4.168184  ],\n",
              "       [4.166746  ],\n",
              "       [2.7407665 ],\n",
              "       [3.087164  ],\n",
              "       [3.5120804 ],\n",
              "       [4.242606  ],\n",
              "       [3.4873958 ],\n",
              "       [3.3131795 ],\n",
              "       [3.3821962 ],\n",
              "       [3.3810463 ],\n",
              "       [2.7809174 ],\n",
              "       [4.1190057 ],\n",
              "       [3.26151   ],\n",
              "       [3.7122788 ],\n",
              "       [3.9916039 ],\n",
              "       [3.7408218 ],\n",
              "       [3.6582904 ],\n",
              "       [3.7368839 ],\n",
              "       [2.813983  ],\n",
              "       [3.6105525 ],\n",
              "       [3.635847  ],\n",
              "       [3.4449914 ],\n",
              "       [3.1816814 ],\n",
              "       [3.5063796 ],\n",
              "       [3.1596413 ],\n",
              "       [3.9629683 ],\n",
              "       [4.2867637 ],\n",
              "       [4.040157  ],\n",
              "       [3.6402216 ],\n",
              "       [3.8606784 ],\n",
              "       [3.771856  ],\n",
              "       [3.3916907 ],\n",
              "       [3.4203367 ],\n",
              "       [3.639056  ],\n",
              "       [2.7134902 ],\n",
              "       [4.4053307 ],\n",
              "       [3.1498404 ],\n",
              "       [3.9439352 ],\n",
              "       [3.8316464 ],\n",
              "       [4.2677875 ],\n",
              "       [3.6702006 ],\n",
              "       [3.5565054 ],\n",
              "       [4.0919056 ],\n",
              "       [3.3427966 ],\n",
              "       [3.1482203 ],\n",
              "       [3.3278885 ],\n",
              "       [3.5666857 ],\n",
              "       [3.6803527 ],\n",
              "       [3.7602246 ],\n",
              "       [3.379474  ],\n",
              "       [3.551422  ],\n",
              "       [4.3289666 ],\n",
              "       [4.2667227 ],\n",
              "       [3.723401  ],\n",
              "       [3.6729105 ],\n",
              "       [3.4889817 ],\n",
              "       [3.5364556 ],\n",
              "       [3.6434517 ],\n",
              "       [3.2926424 ],\n",
              "       [3.1373036 ],\n",
              "       [3.581029  ],\n",
              "       [3.867762  ],\n",
              "       [3.8722005 ],\n",
              "       [3.7931104 ],\n",
              "       [4.0838623 ],\n",
              "       [3.5158477 ],\n",
              "       [3.1884658 ],\n",
              "       [3.5172362 ],\n",
              "       [2.6686783 ],\n",
              "       [3.7303412 ],\n",
              "       [4.0664577 ],\n",
              "       [3.5547295 ],\n",
              "       [3.4137056 ],\n",
              "       [2.831899  ],\n",
              "       [3.2641537 ],\n",
              "       [3.2137856 ],\n",
              "       [3.5206017 ],\n",
              "       [3.7028775 ],\n",
              "       [2.6171045 ],\n",
              "       [3.2885528 ],\n",
              "       [3.5350897 ],\n",
              "       [3.5496507 ],\n",
              "       [3.0445542 ],\n",
              "       [4.443628  ],\n",
              "       [4.1216087 ],\n",
              "       [4.0126886 ],\n",
              "       [3.0053372 ],\n",
              "       [3.970112  ],\n",
              "       [3.29989   ],\n",
              "       [2.9704518 ],\n",
              "       [4.032326  ],\n",
              "       [3.6392174 ],\n",
              "       [2.3880363 ],\n",
              "       [3.5119557 ],\n",
              "       [3.870218  ],\n",
              "       [4.2476907 ],\n",
              "       [2.881884  ],\n",
              "       [3.3249638 ],\n",
              "       [2.439825  ],\n",
              "       [3.6521783 ],\n",
              "       [3.2363396 ],\n",
              "       [3.3423672 ],\n",
              "       [3.268076  ],\n",
              "       [3.8088017 ],\n",
              "       [4.079055  ],\n",
              "       [3.6421995 ],\n",
              "       [2.7422714 ],\n",
              "       [2.937653  ],\n",
              "       [3.612533  ],\n",
              "       [3.620954  ],\n",
              "       [3.3481908 ],\n",
              "       [3.7042646 ],\n",
              "       [3.4088993 ],\n",
              "       [3.7276797 ],\n",
              "       [2.8703508 ],\n",
              "       [3.3910007 ],\n",
              "       [3.7468472 ],\n",
              "       [2.61829   ],\n",
              "       [1.3781617 ],\n",
              "       [2.8337748 ],\n",
              "       [4.1563625 ],\n",
              "       [3.7087882 ],\n",
              "       [4.1685586 ],\n",
              "       [4.100973  ],\n",
              "       [3.5571609 ],\n",
              "       [3.1660976 ],\n",
              "       [4.1223383 ],\n",
              "       [3.3959954 ],\n",
              "       [3.5964842 ],\n",
              "       [2.6936278 ],\n",
              "       [2.9692898 ],\n",
              "       [3.5724614 ],\n",
              "       [3.755083  ],\n",
              "       [3.7580829 ],\n",
              "       [3.3352702 ],\n",
              "       [3.6238663 ],\n",
              "       [3.6788182 ],\n",
              "       [3.4938374 ],\n",
              "       [3.6295867 ],\n",
              "       [3.8814347 ],\n",
              "       [3.6940076 ],\n",
              "       [4.3808556 ],\n",
              "       [3.562984  ],\n",
              "       [3.7747877 ],\n",
              "       [4.115649  ],\n",
              "       [3.4692407 ],\n",
              "       [3.7029262 ],\n",
              "       [3.7668648 ],\n",
              "       [2.4418292 ],\n",
              "       [4.2108283 ],\n",
              "       [3.8833323 ],\n",
              "       [3.4990537 ],\n",
              "       [3.5398455 ],\n",
              "       [4.218582  ],\n",
              "       [4.877659  ],\n",
              "       [3.4841273 ],\n",
              "       [3.7667766 ],\n",
              "       [3.375824  ],\n",
              "       [3.1608913 ],\n",
              "       [3.1981578 ],\n",
              "       [3.541219  ],\n",
              "       [4.3256083 ],\n",
              "       [3.6121192 ],\n",
              "       [3.4916801 ],\n",
              "       [3.3053565 ],\n",
              "       [3.5314102 ],\n",
              "       [3.8094525 ],\n",
              "       [3.4457736 ],\n",
              "       [3.2128212 ],\n",
              "       [2.7935789 ],\n",
              "       [3.1971936 ],\n",
              "       [2.5716763 ],\n",
              "       [3.7581682 ],\n",
              "       [3.271113  ],\n",
              "       [3.1821141 ],\n",
              "       [3.8572068 ],\n",
              "       [3.8288908 ],\n",
              "       [3.9126077 ],\n",
              "       [3.756176  ],\n",
              "       [4.046443  ],\n",
              "       [5.1781263 ],\n",
              "       [3.5737062 ],\n",
              "       [0.83613783],\n",
              "       [3.7807257 ],\n",
              "       [3.0566344 ],\n",
              "       [3.1287253 ],\n",
              "       [3.9857953 ],\n",
              "       [3.367928  ],\n",
              "       [3.7920613 ],\n",
              "       [4.1880636 ],\n",
              "       [3.9283812 ],\n",
              "       [3.856024  ],\n",
              "       [3.896943  ],\n",
              "       [3.3446312 ],\n",
              "       [2.832981  ],\n",
              "       [3.9004908 ],\n",
              "       [3.5181932 ],\n",
              "       [3.2100108 ],\n",
              "       [4.5745745 ],\n",
              "       [3.747213  ],\n",
              "       [3.1822705 ],\n",
              "       [4.156047  ],\n",
              "       [2.75488   ],\n",
              "       [2.005966  ],\n",
              "       [3.8525815 ],\n",
              "       [3.6926613 ],\n",
              "       [3.6263318 ],\n",
              "       [3.9300714 ],\n",
              "       [3.4477017 ],\n",
              "       [3.937222  ],\n",
              "       [3.5531325 ],\n",
              "       [3.837833  ],\n",
              "       [3.7553418 ],\n",
              "       [3.7769108 ],\n",
              "       [4.4101186 ],\n",
              "       [3.3330607 ],\n",
              "       [3.53831   ],\n",
              "       [3.7138226 ],\n",
              "       [3.2849948 ],\n",
              "       [3.6209462 ],\n",
              "       [3.1591127 ],\n",
              "       [3.3981366 ],\n",
              "       [3.2151313 ],\n",
              "       [4.0991535 ],\n",
              "       [3.8346012 ],\n",
              "       [3.7521358 ],\n",
              "       [3.4730363 ],\n",
              "       [3.3905528 ],\n",
              "       [3.8723953 ],\n",
              "       [4.845385  ],\n",
              "       [2.8455248 ],\n",
              "       [4.0910974 ],\n",
              "       [4.062062  ],\n",
              "       [3.459232  ],\n",
              "       [3.6075306 ],\n",
              "       [3.9852543 ],\n",
              "       [3.8333907 ],\n",
              "       [3.7726274 ],\n",
              "       [3.5353265 ],\n",
              "       [1.9867847 ],\n",
              "       [3.7967656 ],\n",
              "       [3.923767  ],\n",
              "       [2.748712  ],\n",
              "       [4.0908036 ],\n",
              "       [2.8191917 ],\n",
              "       [3.294916  ],\n",
              "       [3.1451776 ],\n",
              "       [2.6374478 ],\n",
              "       [4.0514283 ],\n",
              "       [4.0592647 ],\n",
              "       [4.1218286 ],\n",
              "       [3.2735348 ],\n",
              "       [3.3849258 ],\n",
              "       [3.7532744 ],\n",
              "       [3.275687  ],\n",
              "       [3.9570353 ],\n",
              "       [2.7645352 ],\n",
              "       [3.2583563 ],\n",
              "       [4.2936053 ],\n",
              "       [3.4188395 ],\n",
              "       [3.968745  ],\n",
              "       [4.269524  ],\n",
              "       [3.4175916 ],\n",
              "       [3.8822646 ],\n",
              "       [3.0021048 ],\n",
              "       [3.4153855 ],\n",
              "       [1.3616476 ],\n",
              "       [2.8264368 ],\n",
              "       [3.6804404 ],\n",
              "       [3.3497062 ],\n",
              "       [3.6272287 ],\n",
              "       [3.1234303 ],\n",
              "       [3.637765  ],\n",
              "       [3.9092035 ],\n",
              "       [3.6201758 ],\n",
              "       [3.4656386 ],\n",
              "       [3.3239632 ],\n",
              "       [3.469986  ],\n",
              "       [3.789183  ],\n",
              "       [3.9965594 ],\n",
              "       [3.8966646 ],\n",
              "       [3.9004297 ],\n",
              "       [3.1026464 ],\n",
              "       [3.4614258 ],\n",
              "       [3.1926494 ],\n",
              "       [3.8524227 ],\n",
              "       [2.5133185 ],\n",
              "       [3.6661391 ],\n",
              "       [3.9470763 ],\n",
              "       [3.414233  ],\n",
              "       [4.0705094 ],\n",
              "       [3.2292416 ],\n",
              "       [2.5138469 ],\n",
              "       [4.2675986 ],\n",
              "       [2.8556273 ],\n",
              "       [3.5331798 ],\n",
              "       [3.6970396 ],\n",
              "       [4.1501985 ],\n",
              "       [3.603637  ],\n",
              "       [3.4287744 ],\n",
              "       [3.6040118 ],\n",
              "       [4.544516  ],\n",
              "       [3.7371247 ],\n",
              "       [4.264241  ],\n",
              "       [3.5025225 ],\n",
              "       [3.228199  ],\n",
              "       [4.4759088 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "id": "SdWLPbQpnFGC"
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list_cohesion = []\n",
        "for value in prediction_cohesion:\n",
        "  pre_list_cohesion.append(value[0])"
      ],
      "metadata": {
        "id": "M-w7g1LSmmbW"
      },
      "execution_count": 26,
      "outputs": [],
      "id": "M-w7g1LSmmbW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate accuracy for cohesion using vocabulary"
      ],
      "metadata": {
        "id": "TUYkt7CeuC5k"
      },
      "id": "TUYkt7CeuC5k"
    },
    {
      "cell_type": "code",
      "source": [
        "cohesion_accuracy = accuracy_range(pre_list_cohesion, list(test_data['cohesion']))\n",
        "cohesion_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317a6edb-f782-4b99-c3a9-cba56ec54d0d",
        "id": "c65_5Rs9mmbW"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4878671775223499"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "id": "c65_5Rs9mmbW"
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list_2_cohesion = result(pre_list_cohesion)"
      ],
      "metadata": {
        "id": "cMUZyguymmbW"
      },
      "execution_count": 28,
      "outputs": [],
      "id": "cMUZyguymmbW"
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy_2_cohesion = accuracy(list(test_data['cohesion']), pre_list_2_cohesion)\n",
        "val_accuracy_2_cohesion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12472baa-1108-43bc-832d-b5d4ef66e627",
        "id": "dZMOnw3AmmbW"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.22860791826309068"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "id": "dZMOnw3AmmbW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building deep model"
      ],
      "metadata": {
        "id": "RNCJqNXcuITZ"
      },
      "id": "RNCJqNXcuITZ"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_deep(my_learning_rate, my_feature_layer, layers=[20, 12]):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(my_feature_layer)\n",
        "\n",
        "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
        "  # method once for each layer. We've specified the following arguments:\n",
        "  #   * units specifies the number of nodes in this layer.\n",
        "  #   * activation specifies the activation function (Rectified Linear Unit).\n",
        "  #   * name is just a string that can be useful when debugging.\n",
        "\n",
        "  # Define the hidden layers\n",
        "  for index, layer in enumerate(layers):\n",
        "    model.add(tf.keras.layers.Dense(units=layer, \n",
        "                                    activation='relu', \n",
        "                                    name=f'Hidden{index}'))\n",
        "  \n",
        "  # Define the output layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1, name='Output'))                              \n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError(), 'accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "z1zyLNxHk9zF"
      },
      "id": "z1zyLNxHk9zF",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "# Specify the label\n",
        "label_name = \"vocabulary\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "model_deep = create_model_deep(learning_rate, my_feature_layer, [30, 12])\n",
        "# Train the model on the normalized training set. We're passing the entire\n",
        "# normalized training set, but the model will only use the features\n",
        "# defined by the feature_layer.\n",
        "\n",
        "number_epochs = 30\n",
        "\n",
        "mse_train_deep, mse_val_deep = train_model(model_deep, train_data, number_epochs, batch_size, label_name)\n",
        "plot_the_loss_curve(mse_train_deep, mse_val_deep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rbr_t48Fk8mA",
        "outputId": "8841f51c-041d-4a4c-d097-edb65034c0fb"
      },
      "id": "rbr_t48Fk8mA",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/10 [==>...........................] - ETA: 9s - loss: 1315.3337 - mean_squared_error: 1315.3337 - accuracy: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 2s 72ms/step - loss: 269.3230 - mean_squared_error: 269.3230 - accuracy: 0.0000e+00 - val_loss: 113.0506 - val_mean_squared_error: 113.0506 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 41.9386 - mean_squared_error: 41.9386 - accuracy: 0.0000e+00 - val_loss: 9.9882 - val_mean_squared_error: 9.9882 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 11.5165 - mean_squared_error: 11.5165 - accuracy: 0.0000e+00 - val_loss: 4.2458 - val_mean_squared_error: 4.2458 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.8538 - mean_squared_error: 4.8538 - accuracy: 0.0000e+00 - val_loss: 4.2318 - val_mean_squared_error: 4.2318 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.5977 - mean_squared_error: 2.5977 - accuracy: 0.0000e+00 - val_loss: 3.0432 - val_mean_squared_error: 3.0432 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4080 - mean_squared_error: 1.4080 - accuracy: 0.0000e+00 - val_loss: 1.4715 - val_mean_squared_error: 1.4715 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9461 - mean_squared_error: 0.9461 - accuracy: 0.0000e+00 - val_loss: 1.1569 - val_mean_squared_error: 1.1569 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7333 - mean_squared_error: 0.7333 - accuracy: 0.0000e+00 - val_loss: 1.0618 - val_mean_squared_error: 1.0618 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5660 - mean_squared_error: 0.5660 - accuracy: 0.0000e+00 - val_loss: 0.7629 - val_mean_squared_error: 0.7629 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4723 - mean_squared_error: 0.4723 - accuracy: 0.0000e+00 - val_loss: 0.6706 - val_mean_squared_error: 0.6706 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4226 - mean_squared_error: 0.4226 - accuracy: 0.0000e+00 - val_loss: 0.6136 - val_mean_squared_error: 0.6136 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3847 - mean_squared_error: 0.3847 - accuracy: 0.0000e+00 - val_loss: 0.5760 - val_mean_squared_error: 0.5760 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3618 - mean_squared_error: 0.3618 - accuracy: 0.0000e+00 - val_loss: 0.5380 - val_mean_squared_error: 0.5380 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 0.3486 - mean_squared_error: 0.3486 - accuracy: 0.0000e+00 - val_loss: 0.5088 - val_mean_squared_error: 0.5088 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3299 - mean_squared_error: 0.3299 - accuracy: 0.0000e+00 - val_loss: 0.4920 - val_mean_squared_error: 0.4920 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3162 - mean_squared_error: 0.3162 - accuracy: 0.0000e+00 - val_loss: 0.4793 - val_mean_squared_error: 0.4793 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3092 - mean_squared_error: 0.3092 - accuracy: 0.0000e+00 - val_loss: 0.4746 - val_mean_squared_error: 0.4746 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.3014 - mean_squared_error: 0.3014 - accuracy: 0.0000e+00 - val_loss: 0.4593 - val_mean_squared_error: 0.4593 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2970 - mean_squared_error: 0.2970 - accuracy: 0.0000e+00 - val_loss: 0.4501 - val_mean_squared_error: 0.4501 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2941 - mean_squared_error: 0.2941 - accuracy: 0.0000e+00 - val_loss: 0.4476 - val_mean_squared_error: 0.4476 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2928 - mean_squared_error: 0.2928 - accuracy: 0.0000e+00 - val_loss: 0.4482 - val_mean_squared_error: 0.4482 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2932 - mean_squared_error: 0.2932 - accuracy: 0.0000e+00 - val_loss: 0.4272 - val_mean_squared_error: 0.4272 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2859 - mean_squared_error: 0.2859 - accuracy: 0.0000e+00 - val_loss: 0.4216 - val_mean_squared_error: 0.4216 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2837 - mean_squared_error: 0.2837 - accuracy: 0.0000e+00 - val_loss: 0.4159 - val_mean_squared_error: 0.4159 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2807 - mean_squared_error: 0.2807 - accuracy: 0.0000e+00 - val_loss: 0.4082 - val_mean_squared_error: 0.4082 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2786 - mean_squared_error: 0.2786 - accuracy: 0.0000e+00 - val_loss: 0.4081 - val_mean_squared_error: 0.4081 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2776 - mean_squared_error: 0.2776 - accuracy: 0.0000e+00 - val_loss: 0.4008 - val_mean_squared_error: 0.4008 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2776 - mean_squared_error: 0.2776 - accuracy: 0.0000e+00 - val_loss: 0.4251 - val_mean_squared_error: 0.4251 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2837 - mean_squared_error: 0.2837 - accuracy: 0.0000e+00 - val_loss: 0.4058 - val_mean_squared_error: 0.4058 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2771 - mean_squared_error: 0.2771 - accuracy: 0.0000e+00 - val_loss: 0.3996 - val_mean_squared_error: 0.3996 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_features = {name:np.array(value) for name, value in test_data.items()}\n",
        "test_features.pop(\"cohesion\")\n",
        "test_label = np.array(test_features.pop(label_name))# isolate the label\n",
        "\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "result_deep = model_deep.evaluate(x=test_features, y=test_label, batch_size=batch_size)\n",
        "\n",
        "for item in zip(model_deep.metrics_names, result_deep):\n",
        "  print (item[0], item[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3MGM4fF8ldd",
        "outputId": "9ada9206-05d8-4794-f82f-e6e1eb84a753"
      },
      "id": "i3MGM4fF8ldd",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4032 - mean_squared_error: 0.4032 - accuracy: 0.0000e+00\n",
            "loss 0.403239905834198\n",
            "mean_squared_error 0.403239905834198\n",
            "accuracy 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_deep = model_deep.predict(test_features)\n",
        "prediction_deep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75099d8d-415a-4651-fbad-817dece05ae3",
        "id": "tme3doddvMrT"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.820089 ],\n",
              "       [2.9559553],\n",
              "       [2.8183086],\n",
              "       [3.3500142],\n",
              "       [3.1544063],\n",
              "       [3.3771355],\n",
              "       [2.8718116],\n",
              "       [3.1371157],\n",
              "       [3.0004575],\n",
              "       [3.9159105],\n",
              "       [3.2918644],\n",
              "       [3.1445327],\n",
              "       [3.0709002],\n",
              "       [3.353635 ],\n",
              "       [3.2265475],\n",
              "       [3.3175318],\n",
              "       [3.2880652],\n",
              "       [3.7883303],\n",
              "       [2.7932084],\n",
              "       [2.453238 ],\n",
              "       [5.7279234],\n",
              "       [3.48124  ],\n",
              "       [3.6702316],\n",
              "       [3.3859928],\n",
              "       [3.374199 ],\n",
              "       [3.107713 ],\n",
              "       [3.7190578],\n",
              "       [3.125624 ],\n",
              "       [3.5779445],\n",
              "       [3.1080616],\n",
              "       [2.9199197],\n",
              "       [2.8714516],\n",
              "       [3.486142 ],\n",
              "       [4.0191216],\n",
              "       [3.285134 ],\n",
              "       [3.4301765],\n",
              "       [3.0654762],\n",
              "       [3.8711498],\n",
              "       [3.433953 ],\n",
              "       [2.7388732],\n",
              "       [3.4322813],\n",
              "       [3.0438182],\n",
              "       [3.2329366],\n",
              "       [3.5376737],\n",
              "       [2.636893 ],\n",
              "       [3.2575233],\n",
              "       [3.1713521],\n",
              "       [3.3907316],\n",
              "       [3.3097415],\n",
              "       [3.071027 ],\n",
              "       [2.9368792],\n",
              "       [3.1561005],\n",
              "       [2.9521434],\n",
              "       [3.1891472],\n",
              "       [2.8928993],\n",
              "       [3.222185 ],\n",
              "       [3.474281 ],\n",
              "       [3.727186 ],\n",
              "       [3.5642192],\n",
              "       [3.4936123],\n",
              "       [3.3658018],\n",
              "       [4.229926 ],\n",
              "       [3.0259717],\n",
              "       [3.3217275],\n",
              "       [3.6778   ],\n",
              "       [3.6369321],\n",
              "       [2.2739897],\n",
              "       [3.6056325],\n",
              "       [3.0052752],\n",
              "       [3.5020854],\n",
              "       [2.3466504],\n",
              "       [3.7771614],\n",
              "       [3.138018 ],\n",
              "       [2.8055625],\n",
              "       [3.8598545],\n",
              "       [3.5284235],\n",
              "       [3.6778066],\n",
              "       [4.4268103],\n",
              "       [3.2273238],\n",
              "       [2.6328843],\n",
              "       [3.0765834],\n",
              "       [3.1399767],\n",
              "       [3.4149299],\n",
              "       [3.3059309],\n",
              "       [3.5333626],\n",
              "       [3.043502 ],\n",
              "       [3.573774 ],\n",
              "       [3.313106 ],\n",
              "       [3.253762 ],\n",
              "       [3.0170898],\n",
              "       [3.6302938],\n",
              "       [3.3674805],\n",
              "       [3.4442604],\n",
              "       [2.6059597],\n",
              "       [3.0640137],\n",
              "       [3.2019293],\n",
              "       [3.0874276],\n",
              "       [3.9898527],\n",
              "       [3.5252683],\n",
              "       [3.0890074],\n",
              "       [3.2480142],\n",
              "       [2.9960933],\n",
              "       [2.027692 ],\n",
              "       [3.3346827],\n",
              "       [3.1454318],\n",
              "       [3.7443454],\n",
              "       [2.9540393],\n",
              "       [3.228442 ],\n",
              "       [3.237405 ],\n",
              "       [2.9497163],\n",
              "       [4.082368 ],\n",
              "       [3.5672786],\n",
              "       [3.2251112],\n",
              "       [3.071129 ],\n",
              "       [2.9889624],\n",
              "       [3.1815841],\n",
              "       [3.482845 ],\n",
              "       [3.7748654],\n",
              "       [2.8209882],\n",
              "       [2.9406087],\n",
              "       [2.662348 ],\n",
              "       [3.591452 ],\n",
              "       [3.0920928],\n",
              "       [2.335024 ],\n",
              "       [3.319351 ],\n",
              "       [2.6888964],\n",
              "       [3.509795 ],\n",
              "       [3.852513 ],\n",
              "       [3.3589256],\n",
              "       [3.4398623],\n",
              "       [3.0631928],\n",
              "       [2.6653602],\n",
              "       [3.482519 ],\n",
              "       [3.2348635],\n",
              "       [3.6705892],\n",
              "       [3.5828207],\n",
              "       [2.785641 ],\n",
              "       [3.2408693],\n",
              "       [3.2234442],\n",
              "       [3.2833374],\n",
              "       [2.8801394],\n",
              "       [3.8304985],\n",
              "       [3.2327516],\n",
              "       [3.5475347],\n",
              "       [3.5217779],\n",
              "       [3.4782426],\n",
              "       [3.1431508],\n",
              "       [3.2856662],\n",
              "       [3.5523021],\n",
              "       [2.938627 ],\n",
              "       [3.0412843],\n",
              "       [3.371177 ],\n",
              "       [3.49604  ],\n",
              "       [2.9385355],\n",
              "       [3.602678 ],\n",
              "       [3.048227 ],\n",
              "       [2.8629706],\n",
              "       [2.8787086],\n",
              "       [3.1881337],\n",
              "       [2.8627515],\n",
              "       [3.9382493],\n",
              "       [3.379895 ],\n",
              "       [3.036987 ],\n",
              "       [2.8538487],\n",
              "       [3.3855598],\n",
              "       [3.2512715],\n",
              "       [2.961941 ],\n",
              "       [3.9275205],\n",
              "       [3.0432308],\n",
              "       [3.0100126],\n",
              "       [3.267505 ],\n",
              "       [3.165263 ],\n",
              "       [2.8903065],\n",
              "       [3.0555704],\n",
              "       [3.4228864],\n",
              "       [2.9933321],\n",
              "       [2.8387024],\n",
              "       [3.45695  ],\n",
              "       [3.413099 ],\n",
              "       [3.32563  ],\n",
              "       [3.3570795],\n",
              "       [3.6947563],\n",
              "       [3.1872208],\n",
              "       [3.2725627],\n",
              "       [3.5117257],\n",
              "       [3.1596143],\n",
              "       [3.202228 ],\n",
              "       [3.979328 ],\n",
              "       [3.1541553],\n",
              "       [3.1654332],\n",
              "       [2.9011703],\n",
              "       [3.2142508],\n",
              "       [3.9982498],\n",
              "       [3.0578814],\n",
              "       [3.2421672],\n",
              "       [4.2520094],\n",
              "       [4.9785986],\n",
              "       [3.2172701],\n",
              "       [4.480501 ],\n",
              "       [3.4479947],\n",
              "       [3.041313 ],\n",
              "       [2.9388995],\n",
              "       [3.2106473],\n",
              "       [3.072121 ],\n",
              "       [3.5708811],\n",
              "       [3.7405193],\n",
              "       [3.3379133],\n",
              "       [3.794525 ],\n",
              "       [3.1224144],\n",
              "       [2.7411861],\n",
              "       [1.946779 ],\n",
              "       [2.8679886],\n",
              "       [4.6998796],\n",
              "       [2.7539937],\n",
              "       [2.9909694],\n",
              "       [3.4620836],\n",
              "       [3.4017847],\n",
              "       [2.3748968],\n",
              "       [3.5840218],\n",
              "       [3.935477 ],\n",
              "       [4.0216646],\n",
              "       [3.8986437],\n",
              "       [3.7527444],\n",
              "       [4.1753645],\n",
              "       [3.1183193],\n",
              "       [3.244434 ],\n",
              "       [2.834927 ],\n",
              "       [3.0292635],\n",
              "       [3.1098528],\n",
              "       [3.2976334],\n",
              "       [2.8194091],\n",
              "       [3.7153947],\n",
              "       [3.6877785],\n",
              "       [3.0195925],\n",
              "       [2.794071 ],\n",
              "       [3.057214 ],\n",
              "       [3.747193 ],\n",
              "       [2.5570028],\n",
              "       [3.5486114],\n",
              "       [3.5582283],\n",
              "       [3.170616 ],\n",
              "       [3.1137652],\n",
              "       [3.8884609],\n",
              "       [3.6264474],\n",
              "       [3.6027248],\n",
              "       [3.5280077],\n",
              "       [3.4563808],\n",
              "       [3.2781425],\n",
              "       [3.3614295],\n",
              "       [3.3202937],\n",
              "       [3.0491178],\n",
              "       [3.3275664],\n",
              "       [3.728278 ],\n",
              "       [2.885513 ],\n",
              "       [3.3522727],\n",
              "       [9.814583 ],\n",
              "       [3.1902766],\n",
              "       [3.4351323],\n",
              "       [3.8302681],\n",
              "       [3.6057708],\n",
              "       [3.708408 ],\n",
              "       [3.3025937],\n",
              "       [3.0592787],\n",
              "       [3.3824852],\n",
              "       [3.8809955],\n",
              "       [3.553572 ],\n",
              "       [3.2829134],\n",
              "       [3.3363383],\n",
              "       [3.1444852],\n",
              "       [3.9683015],\n",
              "       [3.417361 ],\n",
              "       [3.0295026],\n",
              "       [2.9186828],\n",
              "       [2.9643083],\n",
              "       [3.5307806],\n",
              "       [3.4817684],\n",
              "       [3.3592894],\n",
              "       [2.9134827],\n",
              "       [2.664851 ],\n",
              "       [3.1784112],\n",
              "       [3.1622188],\n",
              "       [2.7384555],\n",
              "       [3.867154 ],\n",
              "       [3.3597434],\n",
              "       [3.912297 ],\n",
              "       [3.2986176],\n",
              "       [2.9074705],\n",
              "       [2.714815 ],\n",
              "       [2.4389837],\n",
              "       [3.3350084],\n",
              "       [3.792958 ],\n",
              "       [2.9751496],\n",
              "       [2.7401776],\n",
              "       [3.2333841],\n",
              "       [3.70726  ],\n",
              "       [4.1188593],\n",
              "       [3.4898012],\n",
              "       [3.1538136],\n",
              "       [3.0331619],\n",
              "       [3.1908543],\n",
              "       [2.3866532],\n",
              "       [3.5594633],\n",
              "       [2.8676097],\n",
              "       [3.5974624],\n",
              "       [3.1166553],\n",
              "       [3.1872044],\n",
              "       [3.8789012],\n",
              "       [3.0549428],\n",
              "       [3.3517005],\n",
              "       [3.2212222],\n",
              "       [3.4436681],\n",
              "       [3.1691024],\n",
              "       [3.0962818],\n",
              "       [2.8941066],\n",
              "       [3.3714056],\n",
              "       [3.2865837],\n",
              "       [3.2608397],\n",
              "       [4.348709 ],\n",
              "       [3.7909925],\n",
              "       [2.918234 ],\n",
              "       [2.9556892],\n",
              "       [3.4531806],\n",
              "       [3.3413446],\n",
              "       [2.6892166],\n",
              "       [3.1532004],\n",
              "       [2.733957 ],\n",
              "       [3.9744022],\n",
              "       [3.5038207],\n",
              "       [2.843305 ],\n",
              "       [2.7485514],\n",
              "       [3.5841472],\n",
              "       [3.0024257],\n",
              "       [4.0828505],\n",
              "       [3.5177603],\n",
              "       [3.063282 ],\n",
              "       [3.753775 ],\n",
              "       [3.2062516],\n",
              "       [2.686548 ],\n",
              "       [3.240475 ],\n",
              "       [3.4497182],\n",
              "       [1.2505062],\n",
              "       [3.2233746],\n",
              "       [3.5426629],\n",
              "       [3.6432445],\n",
              "       [3.820361 ],\n",
              "       [3.284147 ],\n",
              "       [3.0388644],\n",
              "       [3.7291315],\n",
              "       [2.6763713],\n",
              "       [2.8014586],\n",
              "       [3.9547365],\n",
              "       [2.986261 ],\n",
              "       [3.0665357],\n",
              "       [3.8203037],\n",
              "       [3.1396925],\n",
              "       [3.5984337],\n",
              "       [3.0590541],\n",
              "       [2.6604748],\n",
              "       [2.8732986],\n",
              "       [3.5301397],\n",
              "       [2.9179122],\n",
              "       [2.9994838],\n",
              "       [3.0886269],\n",
              "       [3.4858425],\n",
              "       [3.553581 ],\n",
              "       [2.976669 ],\n",
              "       [3.0977626],\n",
              "       [2.8508422],\n",
              "       [3.2365682],\n",
              "       [2.9007425],\n",
              "       [3.0019138],\n",
              "       [3.4126456],\n",
              "       [2.8034413],\n",
              "       [2.8140407],\n",
              "       [2.5673568],\n",
              "       [2.8262422],\n",
              "       [3.342697 ],\n",
              "       [3.1840131],\n",
              "       [3.1133144],\n",
              "       [2.786741 ],\n",
              "       [3.0489924],\n",
              "       [3.0948312],\n",
              "       [3.1673977],\n",
              "       [3.0009222],\n",
              "       [3.330198 ],\n",
              "       [3.726463 ],\n",
              "       [3.0407689],\n",
              "       [2.4054303],\n",
              "       [3.4394538],\n",
              "       [2.8432913],\n",
              "       [3.3052554],\n",
              "       [3.26063  ],\n",
              "       [3.0866902],\n",
              "       [3.744889 ],\n",
              "       [3.6754835],\n",
              "       [2.569382 ],\n",
              "       [3.2191465],\n",
              "       [3.6685464],\n",
              "       [3.4129183],\n",
              "       [2.8292544],\n",
              "       [3.8138835],\n",
              "       [2.6609702],\n",
              "       [3.0100348],\n",
              "       [3.5198238],\n",
              "       [3.33802  ],\n",
              "       [3.3814852],\n",
              "       [2.8629048],\n",
              "       [3.0032847],\n",
              "       [4.089446 ],\n",
              "       [3.571409 ],\n",
              "       [3.5117247],\n",
              "       [3.180061 ],\n",
              "       [3.8987396],\n",
              "       [3.107008 ],\n",
              "       [3.3026054],\n",
              "       [2.662639 ],\n",
              "       [3.1996496],\n",
              "       [3.5213554],\n",
              "       [2.9448264],\n",
              "       [3.200556 ],\n",
              "       [3.3981383],\n",
              "       [3.8865688],\n",
              "       [2.7196739],\n",
              "       [2.871637 ],\n",
              "       [3.3962781],\n",
              "       [3.1957572],\n",
              "       [3.4505749],\n",
              "       [2.9485831],\n",
              "       [3.4360335],\n",
              "       [3.3498266],\n",
              "       [3.104758 ],\n",
              "       [1.1689098],\n",
              "       [3.6305387],\n",
              "       [3.625162 ],\n",
              "       [3.4741766],\n",
              "       [3.1454864],\n",
              "       [3.1796288],\n",
              "       [3.311993 ],\n",
              "       [2.6969182],\n",
              "       [3.3051865],\n",
              "       [3.0667245],\n",
              "       [3.721645 ],\n",
              "       [2.8085592],\n",
              "       [2.73121  ],\n",
              "       [3.1959984],\n",
              "       [3.954356 ],\n",
              "       [4.6182356],\n",
              "       [3.1145895],\n",
              "       [2.814491 ],\n",
              "       [2.8713524],\n",
              "       [3.256325 ],\n",
              "       [3.9318569],\n",
              "       [3.4679358],\n",
              "       [2.7707517],\n",
              "       [2.8507054],\n",
              "       [2.7492101],\n",
              "       [3.9797037],\n",
              "       [4.094078 ],\n",
              "       [3.1019473],\n",
              "       [3.1256425],\n",
              "       [3.2100565],\n",
              "       [3.1759055],\n",
              "       [3.1838324],\n",
              "       [3.1362445],\n",
              "       [3.3314054],\n",
              "       [3.945628 ],\n",
              "       [3.2153287],\n",
              "       [2.8344247],\n",
              "       [3.3186505],\n",
              "       [3.0970612],\n",
              "       [3.4361331],\n",
              "       [3.5017507],\n",
              "       [3.8438685],\n",
              "       [3.9841163],\n",
              "       [3.554921 ],\n",
              "       [4.175783 ],\n",
              "       [3.6128194],\n",
              "       [3.917261 ],\n",
              "       [2.5546103],\n",
              "       [2.6434848],\n",
              "       [3.071007 ],\n",
              "       [3.8333051],\n",
              "       [3.473314 ],\n",
              "       [3.0113623],\n",
              "       [3.026334 ],\n",
              "       [2.84744  ],\n",
              "       [2.9754522],\n",
              "       [3.7951105],\n",
              "       [3.1084936],\n",
              "       [3.2685237],\n",
              "       [3.6253002],\n",
              "       [3.2724073],\n",
              "       [3.2591002],\n",
              "       [3.2396753],\n",
              "       [2.6318061],\n",
              "       [3.227287 ],\n",
              "       [3.1291006],\n",
              "       [3.1500242],\n",
              "       [2.9127614],\n",
              "       [3.0368164],\n",
              "       [3.2409863],\n",
              "       [3.5783236],\n",
              "       [3.8617065],\n",
              "       [3.8918598],\n",
              "       [3.3722513],\n",
              "       [3.3870437],\n",
              "       [3.5778549],\n",
              "       [3.1845505],\n",
              "       [3.396715 ],\n",
              "       [2.9946845],\n",
              "       [2.7847118],\n",
              "       [4.119628 ],\n",
              "       [3.09611  ],\n",
              "       [3.3114097],\n",
              "       [3.3733795],\n",
              "       [3.8209426],\n",
              "       [3.3105218],\n",
              "       [3.2158859],\n",
              "       [3.951599 ],\n",
              "       [3.0575733],\n",
              "       [2.7214618],\n",
              "       [3.1074297],\n",
              "       [3.2165806],\n",
              "       [3.3692749],\n",
              "       [3.425895 ],\n",
              "       [2.9375637],\n",
              "       [3.0351284],\n",
              "       [4.1842318],\n",
              "       [3.672057 ],\n",
              "       [3.371235 ],\n",
              "       [3.456228 ],\n",
              "       [3.3011222],\n",
              "       [3.413953 ],\n",
              "       [3.317127 ],\n",
              "       [3.0320816],\n",
              "       [2.984441 ],\n",
              "       [3.114663 ],\n",
              "       [3.5846705],\n",
              "       [3.3650844],\n",
              "       [2.9524772],\n",
              "       [3.6598203],\n",
              "       [3.1924253],\n",
              "       [2.819903 ],\n",
              "       [3.2947521],\n",
              "       [2.9338424],\n",
              "       [3.3457005],\n",
              "       [3.7896116],\n",
              "       [3.1701722],\n",
              "       [2.9848845],\n",
              "       [3.10785  ],\n",
              "       [2.6679628],\n",
              "       [2.8621514],\n",
              "       [3.421594 ],\n",
              "       [3.147827 ],\n",
              "       [2.9734952],\n",
              "       [2.8548172],\n",
              "       [3.146835 ],\n",
              "       [2.9833395],\n",
              "       [3.1090052],\n",
              "       [4.4040413],\n",
              "       [3.6426947],\n",
              "       [3.46158  ],\n",
              "       [3.1987019],\n",
              "       [3.7578218],\n",
              "       [2.9089017],\n",
              "       [2.9131646],\n",
              "       [3.7113664],\n",
              "       [3.2212312],\n",
              "       [3.1184309],\n",
              "       [3.1991274],\n",
              "       [3.5501835],\n",
              "       [3.9698017],\n",
              "       [2.7953684],\n",
              "       [3.2489448],\n",
              "       [2.6966681],\n",
              "       [3.5267122],\n",
              "       [2.8954856],\n",
              "       [3.3794894],\n",
              "       [3.0579877],\n",
              "       [3.641156 ],\n",
              "       [3.8137758],\n",
              "       [3.370962 ],\n",
              "       [2.7331827],\n",
              "       [2.490502 ],\n",
              "       [3.3670635],\n",
              "       [3.1318285],\n",
              "       [3.5121474],\n",
              "       [3.2155087],\n",
              "       [3.4307601],\n",
              "       [3.410125 ],\n",
              "       [2.6673777],\n",
              "       [3.244974 ],\n",
              "       [3.4528625],\n",
              "       [2.820257 ],\n",
              "       [3.787887 ],\n",
              "       [3.5473337],\n",
              "       [3.767165 ],\n",
              "       [3.353256 ],\n",
              "       [3.7646139],\n",
              "       [3.733093 ],\n",
              "       [3.2197807],\n",
              "       [2.91933  ],\n",
              "       [3.9229066],\n",
              "       [3.02682  ],\n",
              "       [3.248202 ],\n",
              "       [2.3746777],\n",
              "       [2.6063921],\n",
              "       [3.0747755],\n",
              "       [3.4715154],\n",
              "       [3.5560443],\n",
              "       [3.0381427],\n",
              "       [3.3133953],\n",
              "       [3.23537  ],\n",
              "       [3.5148814],\n",
              "       [3.226649 ],\n",
              "       [3.5021365],\n",
              "       [3.3542335],\n",
              "       [4.0836716],\n",
              "       [3.1531193],\n",
              "       [3.3136642],\n",
              "       [3.7759082],\n",
              "       [3.3066   ],\n",
              "       [3.4465644],\n",
              "       [3.4680917],\n",
              "       [2.666351 ],\n",
              "       [3.8635814],\n",
              "       [3.7351682],\n",
              "       [3.074023 ],\n",
              "       [3.0879877],\n",
              "       [3.8011062],\n",
              "       [4.7456703],\n",
              "       [3.4352329],\n",
              "       [3.647826 ],\n",
              "       [3.0604906],\n",
              "       [3.0412042],\n",
              "       [2.7827847],\n",
              "       [3.1954715],\n",
              "       [4.119317 ],\n",
              "       [2.9371345],\n",
              "       [3.2758396],\n",
              "       [3.0632627],\n",
              "       [3.0905268],\n",
              "       [3.5134304],\n",
              "       [2.9504893],\n",
              "       [3.3400543],\n",
              "       [2.9563992],\n",
              "       [2.9330952],\n",
              "       [3.138368 ],\n",
              "       [3.2555497],\n",
              "       [3.1575096],\n",
              "       [2.8860974],\n",
              "       [3.3934815],\n",
              "       [3.4719121],\n",
              "       [3.5867126],\n",
              "       [3.3049958],\n",
              "       [3.645355 ],\n",
              "       [5.121728 ],\n",
              "       [3.197502 ],\n",
              "       [3.1606376],\n",
              "       [3.4031732],\n",
              "       [2.998202 ],\n",
              "       [3.2101903],\n",
              "       [3.823363 ],\n",
              "       [3.0713966],\n",
              "       [3.3708203],\n",
              "       [3.6492531],\n",
              "       [3.363962 ],\n",
              "       [3.492594 ],\n",
              "       [3.5677335],\n",
              "       [3.1177218],\n",
              "       [2.6234064],\n",
              "       [3.5702436],\n",
              "       [3.4657133],\n",
              "       [2.985543 ],\n",
              "       [3.99985  ],\n",
              "       [3.3097222],\n",
              "       [2.8527184],\n",
              "       [3.876414 ],\n",
              "       [2.787172 ],\n",
              "       [2.3131895],\n",
              "       [3.4203632],\n",
              "       [3.2655036],\n",
              "       [3.3163173],\n",
              "       [3.6849868],\n",
              "       [3.3026855],\n",
              "       [3.5903394],\n",
              "       [3.1501224],\n",
              "       [3.436635 ],\n",
              "       [3.5266283],\n",
              "       [3.4000437],\n",
              "       [3.9780443],\n",
              "       [2.9231846],\n",
              "       [3.1707466],\n",
              "       [3.1573102],\n",
              "       [3.0418975],\n",
              "       [3.1473978],\n",
              "       [2.8110256],\n",
              "       [3.0508242],\n",
              "       [3.005103 ],\n",
              "       [3.682305 ],\n",
              "       [3.6127145],\n",
              "       [3.3905737],\n",
              "       [3.0734947],\n",
              "       [3.174688 ],\n",
              "       [3.6352813],\n",
              "       [4.7783003],\n",
              "       [2.6488125],\n",
              "       [3.8796632],\n",
              "       [3.904658 ],\n",
              "       [3.2025142],\n",
              "       [3.092813 ],\n",
              "       [3.6489413],\n",
              "       [3.2540576],\n",
              "       [3.3282645],\n",
              "       [3.420398 ],\n",
              "       [1.4698603],\n",
              "       [3.479789 ],\n",
              "       [3.570543 ],\n",
              "       [3.1539285],\n",
              "       [3.8127286],\n",
              "       [2.501958 ],\n",
              "       [2.6552017],\n",
              "       [3.1835737],\n",
              "       [2.532678 ],\n",
              "       [3.7656744],\n",
              "       [3.510205 ],\n",
              "       [3.8448555],\n",
              "       [2.9080207],\n",
              "       [3.1556046],\n",
              "       [3.4324424],\n",
              "       [2.9148314],\n",
              "       [3.7165725],\n",
              "       [2.7998774],\n",
              "       [3.0217044],\n",
              "       [3.7871735],\n",
              "       [3.013716 ],\n",
              "       [3.5180926],\n",
              "       [3.769695 ],\n",
              "       [3.1338255],\n",
              "       [3.5112388],\n",
              "       [3.0828469],\n",
              "       [3.1802595],\n",
              "       [2.5717695],\n",
              "       [2.6178043],\n",
              "       [3.3059132],\n",
              "       [2.9403484],\n",
              "       [3.227246 ],\n",
              "       [2.7016313],\n",
              "       [3.468917 ],\n",
              "       [3.6023471],\n",
              "       [3.2855494],\n",
              "       [3.1361232],\n",
              "       [2.8794365],\n",
              "       [3.235794 ],\n",
              "       [3.4220784],\n",
              "       [3.6462934],\n",
              "       [3.5536945],\n",
              "       [3.731507 ],\n",
              "       [3.0862305],\n",
              "       [3.0499036],\n",
              "       [2.89838  ],\n",
              "       [3.3363054],\n",
              "       [2.7304177],\n",
              "       [3.4853742],\n",
              "       [3.7566488],\n",
              "       [2.9810312],\n",
              "       [3.626416 ],\n",
              "       [2.8325546],\n",
              "       [2.942184 ],\n",
              "       [4.083254 ],\n",
              "       [2.5780733],\n",
              "       [3.053561 ],\n",
              "       [3.0657341],\n",
              "       [3.721175 ],\n",
              "       [3.419823 ],\n",
              "       [3.004964 ],\n",
              "       [3.349354 ],\n",
              "       [4.516527 ],\n",
              "       [3.2861316],\n",
              "       [4.045783 ],\n",
              "       [3.0406954],\n",
              "       [2.8713074],\n",
              "       [4.348714 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "id": "tme3doddvMrT"
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list_deep = []\n",
        "for value in prediction_deep:\n",
        "  pre_list_deep.append(value[0])"
      ],
      "metadata": {
        "id": "StKOES8wvMrT"
      },
      "execution_count": 36,
      "outputs": [],
      "id": "StKOES8wvMrT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate accuracy for vocabulary"
      ],
      "metadata": {
        "id": "AQVhVBxKvMrT"
      },
      "id": "AQVhVBxKvMrT"
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_accuracy_deep = accuracy_range(pre_list_deep, list(test_data['vocabulary']))\n",
        "vocabulary_accuracy_deep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7152d0cb-51af-44b9-a7a4-0087635da05d",
        "id": "G8LJ6HHJvMrT"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3793103448275862"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "id": "G8LJ6HHJvMrT"
    },
    {
      "cell_type": "code",
      "source": [
        "pre_list_2_deep = result(pre_list_deep)"
      ],
      "metadata": {
        "id": "jGWDFBGrvMrT"
      },
      "execution_count": 38,
      "outputs": [],
      "id": "jGWDFBGrvMrT"
    },
    {
      "cell_type": "code",
      "source": [
        "val_accuracy_2_deep = accuracy(list(test_data['vocabulary']), pre_list_2_deep)\n",
        "val_accuracy_2_deep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "debaad2d-61e1-4aca-c92a-e9d68da7668b",
        "id": "cuG_r-9PvMrT"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "id": "cuG_r-9PvMrT"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Squared Error\")\n",
        "\n",
        "plt.plot(mse_train_lr, label=\"(Training Loss) Linear Model\")\n",
        "plt.plot(mse_train_deep, label=\"(Training Loss) Deep Model\")\n",
        "plt.plot(mse_val_lr, label=\"(Validation Loss) Linear Model\")\n",
        "plt.plot(mse_val_deep, label=\"(Validation Loss) Deep Model\")\n",
        "plt.legend()\n",
        "# plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
        "plt.xticks(range(21))\n",
        "plt.show() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "sBqO8z2gT3p-",
        "outputId": "874d0e3b-4c96-47b2-e65a-6a8008fde7f4"
      },
      "id": "sBqO8z2gT3p-",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "number_epochs = 30\n",
        "batch_size = 256\n",
        "label_name = \"cohesion\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "model_deep_cohesion = create_model_deep(learning_rate, my_new_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "mse_train_deep_cohesion, mse_val_deep_cohesion = train_model(model_deep_cohesion, train_data, number_epochs, batch_size, label_name)\n",
        "#train_history = train_model(model_lr, train_data, number_epochs, batch_size, label_name)\n",
        "plot_the_loss_curve(mse_train_deep_cohesion, mse_val_deep_cohesion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cgkwDdOZu3yN",
        "outputId": "2243034d-dadc-40be-c916-c6983b24eb0e"
      },
      "id": "cgkwDdOZu3yN",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/10 [==>...........................] - ETA: 9s - loss: 2662.4355 - mean_squared_error: 2662.4355 - accuracy: 0.0000e+00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:36' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 2s 74ms/step - loss: 537.2078 - mean_squared_error: 537.2078 - accuracy: 3.9968e-04 - val_loss: 67.9351 - val_mean_squared_error: 67.9351 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 84.3202 - mean_squared_error: 84.3202 - accuracy: 7.9936e-04 - val_loss: 68.7865 - val_mean_squared_error: 68.7865 - val_accuracy: 0.0032\n",
            "Epoch 3/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 30.6396 - mean_squared_error: 30.6396 - accuracy: 0.0016 - val_loss: 21.2517 - val_mean_squared_error: 21.2517 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 10.7460 - mean_squared_error: 10.7460 - accuracy: 0.0012 - val_loss: 5.7383 - val_mean_squared_error: 5.7383 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 4.7967 - mean_squared_error: 4.7967 - accuracy: 0.0016 - val_loss: 2.2368 - val_mean_squared_error: 2.2368 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.4028 - mean_squared_error: 2.4028 - accuracy: 0.0016 - val_loss: 1.9514 - val_mean_squared_error: 1.9514 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.0267 - mean_squared_error: 2.0267 - accuracy: 0.0016 - val_loss: 1.7461 - val_mean_squared_error: 1.7461 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 1.7013 - mean_squared_error: 1.7013 - accuracy: 0.0016 - val_loss: 1.6084 - val_mean_squared_error: 1.6084 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4299 - mean_squared_error: 1.4299 - accuracy: 0.0016 - val_loss: 1.3964 - val_mean_squared_error: 1.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.2455 - mean_squared_error: 1.2455 - accuracy: 0.0016 - val_loss: 1.3151 - val_mean_squared_error: 1.3151 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.1262 - mean_squared_error: 1.1262 - accuracy: 0.0016 - val_loss: 1.2034 - val_mean_squared_error: 1.2034 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0131 - mean_squared_error: 1.0131 - accuracy: 0.0016 - val_loss: 1.0835 - val_mean_squared_error: 1.0835 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9018 - mean_squared_error: 0.9018 - accuracy: 0.0016 - val_loss: 0.9990 - val_mean_squared_error: 0.9990 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7930 - mean_squared_error: 0.7930 - accuracy: 0.0016 - val_loss: 0.8701 - val_mean_squared_error: 0.8701 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.7167 - mean_squared_error: 0.7167 - accuracy: 0.0016 - val_loss: 0.7959 - val_mean_squared_error: 0.7959 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6673 - mean_squared_error: 0.6673 - accuracy: 0.0016 - val_loss: 0.7770 - val_mean_squared_error: 0.7770 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6467 - mean_squared_error: 0.6467 - accuracy: 0.0016 - val_loss: 0.7540 - val_mean_squared_error: 0.7540 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6270 - mean_squared_error: 0.6270 - accuracy: 0.0016 - val_loss: 0.7620 - val_mean_squared_error: 0.7620 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5809 - mean_squared_error: 0.5809 - accuracy: 0.0016 - val_loss: 0.7044 - val_mean_squared_error: 0.7044 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5590 - mean_squared_error: 0.5590 - accuracy: 0.0016 - val_loss: 0.6595 - val_mean_squared_error: 0.6595 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5413 - mean_squared_error: 0.5413 - accuracy: 0.0016 - val_loss: 0.6384 - val_mean_squared_error: 0.6384 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5227 - mean_squared_error: 0.5227 - accuracy: 0.0016 - val_loss: 0.5947 - val_mean_squared_error: 0.5947 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5086 - mean_squared_error: 0.5086 - accuracy: 0.0016 - val_loss: 0.5608 - val_mean_squared_error: 0.5608 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4950 - mean_squared_error: 0.4950 - accuracy: 0.0016 - val_loss: 0.5390 - val_mean_squared_error: 0.5390 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4816 - mean_squared_error: 0.4816 - accuracy: 0.0016 - val_loss: 0.5208 - val_mean_squared_error: 0.5208 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4729 - mean_squared_error: 0.4729 - accuracy: 0.0016 - val_loss: 0.4883 - val_mean_squared_error: 0.4883 - val_accuracy: 0.0016\n",
            "Epoch 27/30\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.4607 - mean_squared_error: 0.4607 - accuracy: 0.0016 - val_loss: 0.4791 - val_mean_squared_error: 0.4791 - val_accuracy: 0.0016\n",
            "Epoch 28/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4534 - mean_squared_error: 0.4534 - accuracy: 0.0016 - val_loss: 0.4657 - val_mean_squared_error: 0.4657 - val_accuracy: 0.0016\n",
            "Epoch 29/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4458 - mean_squared_error: 0.4458 - accuracy: 0.0016 - val_loss: 0.4443 - val_mean_squared_error: 0.4443 - val_accuracy: 0.0032\n",
            "Epoch 30/30\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4348 - mean_squared_error: 0.4348 - accuracy: 0.0016 - val_loss: 0.4441 - val_mean_squared_error: 0.4441 - val_accuracy: 0.0032\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data2 = test_data\n",
        "test_data2.pop(\"vocabulary\")\n",
        "test_data2[\"vocabulary\"] = pre_list_deep\n",
        "test_features_deep_cohesion = {name:np.array(value) for name, value in test_data2.items()}\n",
        "\n",
        "test_label_deep_cohesion = np.array(test_features_deep_cohesion.pop(\"cohesion\"))# isolate the label\n",
        "\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "result_deep_cohesion = model_deep_cohesion.evaluate(x=test_features_deep_cohesion, y=test_label_deep_cohesion, batch_size=batch_size)\n",
        "\n",
        "for item in zip(model_deep_cohesion.metrics_names, result_deep_cohesion):\n",
        "  print (item[0], item[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k28t5C00-UnN",
        "outputId": "e7de4783-7aba-4cc1-c2de-be79a4940fc0"
      },
      "id": "k28t5C00-UnN",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4314 - mean_squared_error: 0.4314 - accuracy: 0.0051\n",
            "loss 0.43143004179000854\n",
            "mean_squared_error 0.43143004179000854\n",
            "accuracy 0.0051085567101836205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_features_deep_cohesion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN29JvCMEghR",
        "outputId": "b2f2efb6-620f-4eae-8982-fc32f4c868d7"
      },
      "id": "dN29JvCMEghR",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_deep_cohesion = model_deep_cohesion.predict(test_features_deep_cohesion)\n",
        "pre_list_deep_cohesion = []\n",
        "for value in prediction_deep_cohesion:\n",
        "  pre_list_deep_cohesion.append(value[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjwwrJJQ_Tp3",
        "outputId": "4b4f024a-343d-484c-aed4-1e6de3f56433"
      },
      "id": "KjwwrJJQ_Tp3",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'IteratorGetNext:24' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'IteratorGetNext:31' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'IteratorGetNext:26' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'IteratorGetNext:15' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'IteratorGetNext:10' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'IteratorGetNext:11' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'IteratorGetNext:27' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'IteratorGetNext:16' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'IteratorGetNext:28' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'IteratorGetNext:30' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'IteratorGetNext:29' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'IteratorGetNext:21' shape=(None,) dtype=int64>, 'num_of_short_forms': <tf.Tensor 'IteratorGetNext:22' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'IteratorGetNext:32' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'IteratorGetNext:19' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'IteratorGetNext:23' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'IteratorGetNext:33' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'IteratorGetNext:17' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'IteratorGetNext:18' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'IteratorGetNext:12' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'IteratorGetNext:14' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'IteratorGetNext:13' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'IteratorGetNext:20' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'IteratorGetNext:34' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'IteratorGetNext:25' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'IteratorGetNext:35' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cohesion_deep_accuracy = accuracy_range(pre_list_deep_cohesion, list(test_data['cohesion']))\n",
        "cohesion_deep_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9uWXYLBACMx",
        "outputId": "4a050fb8-1566-4197-d612-853f787ec29c"
      },
      "id": "o9uWXYLBACMx",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5427841634738186"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(model_deep, open('nn_model_vocabulary.sav', 'wb'))\n",
        "pickle.dump(model_deep_cohesion, open('nn_model_cohesion.sav', 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb4nJPzaJ-uY",
        "outputId": "e05f9736-d511-4972-b263-ed15161c9413"
      },
      "id": "Lb4nJPzaJ-uY",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'phrase_diversity:0' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'cohesion:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs_26:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs_33:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs_28:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs_17:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs_10:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs_11:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs_12:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs_13:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs_29:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs_18:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs_30:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs_32:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs_31:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs_23:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs_24:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs_8:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs_34:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs_21:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs_25:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs_9:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs_35:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs_19:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs_20:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs_14:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs_16:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs_15:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs_22:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs_36:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs_27:0' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs_26:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs_33:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs_28:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs_17:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs_10:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs_11:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs_12:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs_13:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs_29:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs_18:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs_30:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs_32:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs_31:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs_23:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs_24:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs_8:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs_34:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs_21:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs_25:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs_9:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs_35:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs_19:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs_20:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs_14:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs_16:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs_15:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs_22:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs_36:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs_27:0' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'phrase_diversity:0' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'cohesion:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'phrase_diversity:0' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'cohesion:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:absl:Function `_wrapped_model` contains input name(s) ARI, Incorrect_form_ratio with unsupported characters which will be renamed to ari, incorrect_form_ratio in the SavedModel.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs/number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs/stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs/av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs/punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs/ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs/freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs/freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs/freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs/freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs/freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs/sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs/freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs/sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs/sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs/sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs/num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs/corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs/num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs/Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs/flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs/flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs/dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs/text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs/mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs/number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs/freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs/ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs/coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs/lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs/lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs/freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs/freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs/freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs/noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs/verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs/phrase_diversity:0' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'inputs/cohesion:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs/number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs/stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs/av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs/punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs/ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs/freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs/freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs/freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs/freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs/freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs/sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs/freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs/sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs/sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs/sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs/num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs/corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs/num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs/Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs/flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs/flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs/dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs/text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs/mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs/number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs/freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs/ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs/coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs/lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs/lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs/freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs/freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs/freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs/noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs/verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs/phrase_diversity:0' shape=(None,) dtype=float32>, 'cohesion': <tf.Tensor 'inputs/cohesion:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'phrase_diversity:0' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'vocabulary:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs_25:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs_32:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs_27:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs_16:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs_9:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs_10:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs_11:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs_12:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs_28:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs_17:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs_29:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs_31:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs_30:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs_22:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs_23:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs_33:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs_20:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs_24:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs_8:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs_34:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs_18:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs_19:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs_13:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs_15:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs_14:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs_21:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs_35:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs_26:0' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'inputs_36:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs_25:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs_32:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs_2:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs_27:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs_16:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs_9:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs_10:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs_11:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs_12:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs_28:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs_17:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs_29:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs_31:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs_30:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs_22:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs_4:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs_23:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs_1:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs_7:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs_6:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs_5:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs_33:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs_20:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs_24:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs_8:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs_34:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs_3:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs_18:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs_19:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs_13:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs_15:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs_14:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs_21:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs_35:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs_26:0' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'inputs_36:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'phrase_diversity:0' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'vocabulary:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'phrase_diversity:0' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'vocabulary:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:absl:Function `_wrapped_model` contains input name(s) ARI, Incorrect_form_ratio with unsupported characters which will be renamed to ari, incorrect_form_ratio in the SavedModel.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs/number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs/stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs/av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs/punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs/ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs/freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs/freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs/freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs/freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs/freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs/sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs/freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs/sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs/sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs/sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs/num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs/corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs/num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs/Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs/flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs/flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs/dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs/text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs/mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs/number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs/freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs/ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs/coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs/lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs/lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs/freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs/freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs/freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs/noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs/verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs/phrase_diversity:0' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'inputs/vocabulary:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'number_of_words': <tf.Tensor 'inputs/number_of_words:0' shape=(None,) dtype=int64>, 'stopwords_frequency': <tf.Tensor 'inputs/stopwords_frequency:0' shape=(None,) dtype=float32>, 'av_word_per_sen': <tf.Tensor 'inputs/av_word_per_sen:0' shape=(None,) dtype=float32>, 'punctuations': <tf.Tensor 'inputs/punctuations:0' shape=(None,) dtype=float32>, 'ARI': <tf.Tensor 'inputs/ARI:0' shape=(None,) dtype=int64>, 'freq_of_verb': <tf.Tensor 'inputs/freq_of_verb:0' shape=(None,) dtype=float32>, 'freq_of_adj': <tf.Tensor 'inputs/freq_of_adj:0' shape=(None,) dtype=float32>, 'freq_of_adv': <tf.Tensor 'inputs/freq_of_adv:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adj': <tf.Tensor 'inputs/freq_of_distinct_adj:0' shape=(None,) dtype=float32>, 'freq_of_distinct_adv': <tf.Tensor 'inputs/freq_of_distinct_adv:0' shape=(None,) dtype=float32>, 'sentence_complexity': <tf.Tensor 'inputs/sentence_complexity:0' shape=(None,) dtype=float32>, 'freq_of_wrong_words': <tf.Tensor 'inputs/freq_of_wrong_words:0' shape=(None,) dtype=float32>, 'sentiment_compound': <tf.Tensor 'inputs/sentiment_compound:0' shape=(None,) dtype=float32>, 'sentiment_positive': <tf.Tensor 'inputs/sentiment_positive:0' shape=(None,) dtype=float32>, 'sentiment_negative': <tf.Tensor 'inputs/sentiment_negative:0' shape=(None,) dtype=float32>, 'num_of_grammar_errors': <tf.Tensor 'inputs/num_of_grammar_errors:0' shape=(None,) dtype=int64>, 'corrected_text': <tf.Tensor 'inputs/corrected_text:0' shape=(None,) dtype=string>, 'num_of_short_forms': <tf.Tensor 'inputs/num_of_short_forms:0' shape=(None,) dtype=int64>, 'Incorrect_form_ratio': <tf.Tensor 'inputs/Incorrect_form_ratio:0' shape=(None,) dtype=float32>, 'flesch_reading_ease': <tf.Tensor 'inputs/flesch_reading_ease:0' shape=(None,) dtype=float32>, 'flesch_kincaid_grade': <tf.Tensor 'inputs/flesch_kincaid_grade:0' shape=(None,) dtype=float32>, 'dale_chall_readability_score': <tf.Tensor 'inputs/dale_chall_readability_score:0' shape=(None,) dtype=float32>, 'text_standard': <tf.Tensor 'inputs/text_standard:0' shape=(None,) dtype=float32>, 'mcalpine_eflaw': <tf.Tensor 'inputs/mcalpine_eflaw:0' shape=(None,) dtype=float32>, 'number_of_diff_words': <tf.Tensor 'inputs/number_of_diff_words:0' shape=(None,) dtype=int64>, 'freq_diff_words': <tf.Tensor 'inputs/freq_diff_words:0' shape=(None,) dtype=float32>, 'ttr': <tf.Tensor 'inputs/ttr:0' shape=(None,) dtype=float32>, 'coherence_score': <tf.Tensor 'inputs/coherence_score:0' shape=(None,) dtype=float32>, 'lexrank_avg_min_diff': <tf.Tensor 'inputs/lexrank_avg_min_diff:0' shape=(None,) dtype=float32>, 'lexrank_interquartile': <tf.Tensor 'inputs/lexrank_interquartile:0' shape=(None,) dtype=float32>, 'freq_of_noun': <tf.Tensor 'inputs/freq_of_noun:0' shape=(None,) dtype=float32>, 'freq_of_transition': <tf.Tensor 'inputs/freq_of_transition:0' shape=(None,) dtype=float32>, 'freq_of_pronoun': <tf.Tensor 'inputs/freq_of_pronoun:0' shape=(None,) dtype=float32>, 'noun_to_adj': <tf.Tensor 'inputs/noun_to_adj:0' shape=(None,) dtype=float32>, 'verb_to_adv': <tf.Tensor 'inputs/verb_to_adv:0' shape=(None,) dtype=float32>, 'phrase_diversity': <tf.Tensor 'inputs/phrase_diversity:0' shape=(None,) dtype=float32>, 'vocabulary': <tf.Tensor 'inputs/vocabulary:0' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model_vocabulary = pickle.load(open(\"nn_model_vocabulary.sav\", 'rb'))\n",
        "nn_model_cohesion = pickle.load(open(\"nn_model_cohesion.sav\", 'rb'))"
      ],
      "metadata": {
        "id": "Y6KZhhzPKo1-"
      },
      "id": "Y6KZhhzPKo1-",
      "execution_count": 51,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}